{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/flobotics/colab/blob/master/Untitled0.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "uIoxiS-HCAFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "kbxXAjLSCkrb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir dopamine-rl\n",
        "!pip install cmake\n",
        "!pip install atari_py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2_FsXUaCrMu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from dopamine.agents.dqn import dqn_agent\n",
        "from dopamine.atari import run_experiment\n",
        "from dopamine.colab import utils as colab_utils\n",
        "from absl import flags\n",
        "\n",
        "BASE_PATH = '/tmp/colab_dope_run'\n",
        "GAME = 'Asterix'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMQdGfOPFOPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_PATH = os.path.join(BASE_PATH, 'basic_agent', GAME)\n",
        "\n",
        "class BasicAgent(object):\n",
        "  \n",
        "  def __init__(self, sess, num_actions, switch_prob=0.1):\n",
        "    self._sess = sess\n",
        "    self._num_actions = num_actions\n",
        "    self._switch_prob = switch_prob\n",
        "    self._last_action = np.random.randint(num_actions)\n",
        "    self.eval_mode = False\n",
        "    \n",
        "    \n",
        "    \n",
        "  def __choose_action(self):\n",
        "    if np.random.random <= self._switch_prob:\n",
        "      self._last_action = np.random.random(self._num_actions)\n",
        "    return self._last_action\n",
        "    \n",
        "  def bundle_and_checkpoint(self, unused_checkpoint_dir, unused_iteration):\n",
        "    pass\n",
        "  \n",
        "  def unbundle(self, unused_checkpoint_dir, unused_checkpoint_version, unused_data):\n",
        "    pass\n",
        "  \n",
        "  def begin_episode(self, unused_observation):\n",
        "    pass\n",
        "  \n",
        "  def step(self, reward, observation):\n",
        "    return self._choose_action()\n",
        "  \n",
        "  \n",
        "  \n",
        "def create_basic_agent(sess, environment):\n",
        "  return BasicAgent(sess, num_actions=environment.action_space.n, switch_prob=0.2)\n",
        "  \n",
        "basic_runner = run_experiment.Runner(LOG_PATH,\n",
        "                                      create_basic_agent,\n",
        "                                      game_name=GAME,\n",
        "                                      num_iterations=200,\n",
        "                                      training_steps=10,\n",
        "                                      evaluation_steps=10,\n",
        "                                      max_steps_per_episode=100)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}