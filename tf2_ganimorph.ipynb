{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2-ganimorph.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flobotics/colab/blob/master/tf2_ganimorph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3N_53xvtUQb",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/alpha/tutorials/generative/pix2pix\n",
        "\n",
        "https://www.tensorflow.org/alpha/tutorials/generative/dcgan\n",
        "\n",
        "https://www.tensorflow.org/alpha/tutorials/load_data/images#load_and_format_the_images\n",
        "\n",
        "https://www.tensorflow.org/guide/performance/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B53NJP7dt9xT",
        "colab_type": "text"
      },
      "source": [
        "@inproceedings{Gokaslan2018,\n",
        "  title={Improving Shape Deformation in Unsupervised Image to Image Translation},\n",
        "  author={Aaron Gokaslan and Vivek Ramanujan and Daniel Ritchie and Kwang In Kim and James Tompkin},\n",
        "  booktitle={European Conference on Computer Vision},\n",
        "  year={2018}\n",
        "}\n",
        "\n",
        "https://github.com/brownvc/ganimorph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAJoNuk5QHU2",
        "colab_type": "code",
        "outputId": "55b4c9cb-1707-4b0c-fa28-8b578f340a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXrMqG2hntC5",
        "colab_type": "code",
        "outputId": "2a2d75f7-f91f-4eb1-93e9-0253d3e1533f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip3 install tensorflow-addons"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4FTapNoc7N5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "#from tensorpack import *\n",
        "#from tensorpack.utils.viz import *\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "#from tensorpack import (FeedfreeTrainerBase, QueueInput,\n",
        "#                        ModelDesc, DataFlow, StagingInputWrapper,\n",
        "#                        MultiGPUTrainerBase, LeastLoadedDeviceSetter)\n",
        "#from tensorpack.tfutils.summary import add_moving_summary\n",
        "\n",
        "from tensorflow.python.training import moving_averages\n",
        "\n",
        "\n",
        "#import tensorpack.tfutils.symbolic_functions as symbf\n",
        "\n",
        "import cv2\n",
        "import os, sys\n",
        "import argparse\n",
        "from six.moves import map, zip\n",
        "from glob import glob\n",
        "\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#from tensorpack import *\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import IPython.display as display\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42GSJFUiZmZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.executing_eagerly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLpmUIEpKQSl",
        "colab_type": "text"
      },
      "source": [
        "# Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkcpyr6heK4C",
        "colab_type": "code",
        "outputId": "a1894263-ec08-4294-822c-91a30b838365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeSB753GeZZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir /content/log\n",
        "#!cp -a /content/gdrive/My\\ Drive/images/model-11/* /content/log/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMhjxVqpgH3M",
        "colab_type": "text"
      },
      "source": [
        "# Copy train and test data from e.g. Google-Drive to colab-notebook-machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaIQ_Lw5ebCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/data/\n",
        "\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/trainA.tar.gz /content/data/\n",
        "!tar -xzf /content/data/trainA.tar.gz -C /content/data/\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/trainB.tar.gz /content/data/\n",
        "!tar -xzf /content/data/trainB.tar.gz -C /content/data/\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/testA.tar.gz /content/data/\n",
        "!tar -xzf /content/data/testA.tar.gz -C /content/data/\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/testB.tar.gz /content/data/\n",
        "!tar -xzf /content/data/testB.tar.gz -C /content/data/\n",
        "\n",
        "!rm /content/data/testA.tar.gz\n",
        "!rm /content/data/testB.tar.gz\n",
        "!rm /content/data/trainA.tar.gz\n",
        "!rm /content/data/trainB.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMABggQHRw0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SHAPE = 128\n",
        "#BATCH = 16\n",
        "TEST_BATCH = 32\n",
        "NF = 64  # channel size\n",
        "\n",
        "BATCH_SIZE  = 2\n",
        "#FLAGS.batch_size = BATCH\n",
        "#FLAGS.prefetch_buffer_size = BATCH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnqVhD777SF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_preprocess_image(path):\n",
        "  print_debug = 1\n",
        "  \n",
        "  image = tf.io.read_file(path)\n",
        "  \n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  if print_debug: print(\"original image-shape:{}\".format(image.shape))\n",
        "  if print_debug: print(\"original image-dtype:{}\".format(image.dtype))\n",
        "  \n",
        "  image = tf.image.resize(image, [SHAPE, SHAPE])\n",
        "  image /= 255.0  # normalize to [0,1] range\n",
        "  image = tf.transpose(image, perm=[2, 0, 1]) #seemed to break something, transpose ZipDataset\n",
        "\n",
        "  if print_debug: print(\"preprocessed image-shape:{}\".format(image.shape))\n",
        "  #if print_debug: print(\"preprocessed image-numpy-min:{}\".format(image.numpy().min()))\n",
        "  #if print_debug: print(\"preprocessed image-numpy-max:{}\".format(image.numpy().max()))\n",
        "  \n",
        "  return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPreL8O1EP3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_image_paths(dir):\n",
        "  print_debug = 0\n",
        "  \n",
        "  data_root = pathlib.Path(dir)\n",
        "  if print_debug: print(\"image-dir:{}\".format(data_root))\n",
        "  \n",
        "  all_image_paths = list(data_root.glob('*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  if print_debug: print(\"image-count:{}\".format(len(all_image_paths)))\n",
        "  \n",
        "  if print_debug:\n",
        "    print(\"3 Pictures from this set\")\n",
        "    for n in range(3):\n",
        "      image_path = random.choice(all_image_paths)\n",
        "      display.display(display.Image(image_path))\n",
        "    \n",
        "  return all_image_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQDEdSKrLXNF",
        "colab_type": "text"
      },
      "source": [
        "# Build Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7NAZUxrRZr4",
        "colab_type": "code",
        "outputId": "858f014a-f01a-4363-e055-88b272f3c31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print_debug = 1\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "trainA_dir = \"/content/data/trainA\"\n",
        "trainB_dir = \"/content/data/trainB\"\n",
        "testA_dir = \"/content/data/testA\"\n",
        "testB_dir = \"/content/data/testB\"\n",
        "\n",
        "#---Create Dataset with trainA\n",
        "all_image_paths = get_all_image_paths(trainA_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_trainA = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_trainA))\n",
        "\n",
        "#---Create Dataset with trainB\n",
        "all_image_paths = get_all_image_paths(trainB_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_trainB = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_trainA))\n",
        "\n",
        "  #--- Create ZipDataset\n",
        "image_ds_trainA_B = tf.data.Dataset.zip((image_ds_trainA, image_ds_trainB))\n",
        "if print_debug: print(\"zipDataset  shapes/types:{}\".format(image_ds_trainA_B))\n",
        "\n",
        "#---Create Dataset with testA\n",
        "all_image_paths = get_all_image_paths(testA_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_testA = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_testA))\n",
        "\n",
        "#---Create Dataset with testB\n",
        "all_image_paths = get_all_image_paths(testB_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_testB = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_testB))\n",
        "\n",
        "#--- Create ZipDataset\n",
        "image_ds_testA_B = tf.data.Dataset.zip((image_ds_testA, image_ds_testB))\n",
        "if print_debug: print(\"zipDataset  shapes/types:{}\".format(image_ds_testA_B))\n",
        "#print(\"len:{}\".format(image_ds_testA_B.))\n",
        "\n",
        "#------\n",
        "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
        "# completely shuffled.\n",
        "image_ds_trainA_B = image_ds_trainA_B.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "image_ds_trainA_B = image_ds_trainA_B.repeat()\n",
        "image_ds_trainA_B = image_ds_trainA_B.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=SHUFFLE_BUFFER_SIZE))\n",
        "image_ds_trainA_B = image_ds_trainA_B.batch(BATCH_SIZE)\n",
        "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
        "image_ds_trainA_B = image_ds_trainA_B.prefetch(buffer_size=AUTOTUNE)\n",
        "if print_debug: print(\"image_ds_trainA_B shape/type {}\".format(image_ds_trainA_B))\n",
        "\n",
        "#test-images ds\n",
        "image_ds_testA_B = image_ds_testA_B.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "image_ds_testA_B = image_ds_testA_B.repeat()\n",
        "image_ds_testA_B = image_ds_testA_B.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=SHUFFLE_BUFFER_SIZE))\n",
        "image_ds_testA_B = image_ds_testA_B.batch(BATCH_SIZE)\n",
        "image_ds_testA_B = image_ds_testA_B.prefetch(buffer_size=AUTOTUNE)\n",
        "if print_debug: print(\"image_ds_testA_B shape/type {}\".format(image_ds_testA_B))\n",
        "\n",
        "  \n",
        "#for input_image, target in image_ds_testA_B:\n",
        "#  print(\"out:{} {}\".format(input_image, target))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "zipDataset  shapes/types:<ZipDataset shapes: ((3, 128, 128), (3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "zipDataset  shapes/types:<ZipDataset shapes: ((3, 128, 128), (3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "image_ds_trainA_B shape/type <PrefetchDataset shapes: ((None, 3, 128, 128), (None, 3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "image_ds_testA_B shape/type <PrefetchDataset shapes: ((None, 3, 128, 128), (None, 3, 128, 128)), types: (tf.float32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qNnanKKTMCo",
        "colab_type": "text"
      },
      "source": [
        "# build the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLpSzPzunVqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def INReLU(self,x, name=None):\n",
        "  x = tfa.layers.InstanceNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTurwOdnnZhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def INLReLU(x, name=None):\n",
        "  #x = tfa.layers.InstanceNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hONyQzQ6ndz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BNLReLU(x, name):\n",
        "    x = BatchNorm('bn', x)\n",
        "    return tf.nn.relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHpB6pfI-Je1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = \"channels_first\"\n",
        "debug_show_shapes = 0\n",
        "res_input = tf.Variable([3, 128, 128])\n",
        "res_l = tf.Variable([3, 128, 128])\n",
        "\n",
        "def build_res_block(x, name, chan, first=False):\n",
        "  #input = x\n",
        "  print(\"x-shape:{}\".format(x))\n",
        "  res_input = x\n",
        "  l = layers.Conv2D(filters=NF*2,\n",
        "                    kernel_size=3,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    data_format=df,\n",
        "                    kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                    use_bias=False)(x)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "  l = layers.Conv2D(filters=NF*2,\n",
        "                    kernel_size=3,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    data_format=df,\n",
        "                    kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                    use_bias=False)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "  #l = tf.concat([l, input], axis=1)\n",
        "  l = tf.concat([l, res_input], axis=1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "  l = layers.Conv2D(filters=NF*2,\n",
        "                    kernel_size=3,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    data_format=df,\n",
        "                    kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                    use_bias=False)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"layer1: {}\".format(l.shape))\n",
        "  \n",
        "  return l\n",
        "\n",
        "def res_group(input, name, depth, channels):\n",
        "  res_l = input\n",
        "  for k in range(depth):\n",
        "    res_l = build_res_block(res_l, name + ('/res%d' % k), channels,\n",
        "                           first=(k==0))\n",
        "    \n",
        "  return res_l\n",
        "  \n",
        "#def res_group(input, name, depth, channels):\n",
        "#  l = input\n",
        "#  for k in range(depth):\n",
        "#    l = build_res_block(l, name + ('/res%d' % k), channels,\n",
        "#            first=(k==0))\n",
        "#  return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv6fy9A-qOz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug_show_shapes = 1\n",
        "subDepth = 3\n",
        "df = \"channels_first\"\n",
        "inputs = tf.keras.Input(shape=(3, 128, 128)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPs8FP-Hle1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "   # Returns a placeholder tensor\n",
        "  \n",
        "\n",
        "  \n",
        "  if debug_show_shapes: print(\"inputs: {}\".format(inputs.shape))\n",
        "  \n",
        "  conv0 = layers.Conv2D(filters=NF, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=tf.nn.relu, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(inputs)\n",
        "  \n",
        "  if debug_show_shapes: print(\"conv0: {}\".format(conv0.shape))\n",
        "  \n",
        "  conv1 = layers.Conv2D(filters=NF*2,\n",
        "                        kernel_size=4,\n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        data_format=df,\n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                        use_bias=False,\n",
        "                        activation=INLReLU)(conv0)\n",
        "\n",
        "  if debug_show_shapes: print(\"conv1: {}\".format(conv1.shape))\n",
        "  \n",
        "  #-------------------------\n",
        "  layer1 = res_group(conv1, 'layer1', subDepth, NF*2)\n",
        "  \n",
        "  #-----------------\n",
        "  conv2 = layers.Conv2D(filters=NF*4,\n",
        "                        kernel_size=4,\n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        data_format=df,\n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                        use_bias=False,\n",
        "                        activation=INLReLU)(layer1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"conv2: {}\".format(conv2.shape))\n",
        "  #----------------\n",
        "  \n",
        "  layer2 = res_group(conv2, 'layer2', subDepth, NF*4)\n",
        "  \n",
        "  #-----------------\n",
        "  conv3 = layers.Conv2D(filters=NF*8,\n",
        "                        kernel_size=4,\n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        data_format=df,\n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                        use_bias=False,\n",
        "                        activation=INLReLU)(layer2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"conv3: {}\".format(conv3.shape))\n",
        "  #---------------\n",
        "  l = res_group(conv3, 'layer3', subDepth, NF*8)\n",
        "  \n",
        "  #--------------\n",
        "  \n",
        "  deconv0 = layers.Conv2DTranspose(filters=NF*4,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False,\n",
        "                                   activation=INLReLU)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv0: {}\".format(deconv0.shape))\n",
        "  #-----------------\n",
        "  up1 = tf.concat([deconv0, layer2], axis=1)\n",
        "  \n",
        "  #------------\n",
        "  b_layer_2 = res_group(up1, 'blayer2', subDepth, NF * 4)\n",
        "  \n",
        "  #----------\n",
        "  deconv1 = layers.Conv2DTranspose(filters=NF*2,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False,\n",
        "                                   activation=INLReLU)(b_layer_2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv1: {}\".format(deconv1.shape))\n",
        "  \n",
        "  #-----------\n",
        "  up2 = tf.concat([deconv1, layer1], axis=1)\n",
        "  \n",
        "  #------------\n",
        "  b_layer_1 = res_group(up2, 'blayer1', subDepth, NF * 2)\n",
        "  \n",
        "  #----------\n",
        "  deconv2 = layers.Conv2DTranspose(filters=NF*1,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False,\n",
        "                                   activation=INLReLU)(b_layer_1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv2: {}\".format(deconv2.shape))\n",
        "  #-----------\n",
        "  deconv3 = layers.Conv2DTranspose(filters=3,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False, \n",
        "                                   activation=tf.sigmoid)(deconv2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv3: {}\".format(deconv3.shape))\n",
        "  #-----------\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=deconv3)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvSfrg0mUISo",
        "colab_type": "code",
        "outputId": "e99b394b-0a80-487b-ace0-1aa920ceb45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2445
        }
      },
      "source": [
        "generator = Generator()\n",
        "\n",
        "\n",
        "noise = tf.random.normal([1, 3, 128, 128])\n",
        "\n",
        "i = image_ds_testA.take(1)\n",
        "print(\"i:{}\".format(list(i)))\n",
        "\n",
        "\n",
        "\n",
        "gen_output = generator(noise, training=False)\n",
        "\n",
        "gen_output = tf.transpose(gen_output, [0, 2, 3, 1])\n",
        "print(gen_output.shape)\n",
        "\n",
        "plt.imshow(gen_output[0,...])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: (None, 3, 128, 128)\n",
            "conv0: (None, 64, 64, 64)\n",
            "conv1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_1/re_lu/Relu:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_4/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_7/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "conv2: (None, 256, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_11/re_lu_1/Relu:0\", shape=(None, 256, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 384, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_14/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_17/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "conv3: (None, 512, 8, 8)\n",
            "x-shape:Tensor(\"conv2d_21/re_lu_2/Relu:0\", shape=(None, 512, 8, 8), dtype=float32)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 640, 8, 8)\n",
            "layer1: (None, 128, 8, 8)\n",
            "x-shape:Tensor(\"conv2d_24/Conv2D:0\", shape=(None, 128, 8, 8), dtype=float32)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 256, 8, 8)\n",
            "layer1: (None, 128, 8, 8)\n",
            "x-shape:Tensor(\"conv2d_27/Conv2D:0\", shape=(None, 128, 8, 8), dtype=float32)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 256, 8, 8)\n",
            "layer1: (None, 128, 8, 8)\n",
            "deconv0: (None, 256, 16, 16)\n",
            "x-shape:Tensor(\"concat_9:0\", shape=(None, 384, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 512, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_33/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_36/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "deconv1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"concat_13:0\", shape=(None, 256, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 384, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_42/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_45/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "deconv2: (None, 64, 64, 64)\n",
            "deconv3: (None, 3, 128, 128)\n",
            "i:[<tf.Tensor: id=1274, shape=(3, 128, 128), dtype=float32, numpy=\n",
            "array([[[0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        ...,\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843]],\n",
            "\n",
            "       [[0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        ...,\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843]],\n",
            "\n",
            "       [[0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        ...,\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843],\n",
            "        [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843,\n",
            "         0.99607843, 0.99607843]]], dtype=float32)>]\n",
            "(1, 128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff20047b080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwuDmsZMy9CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGQRQzOfttj7",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFvOoSsVaj03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "  debug_show_shapes = 0\n",
        "  \n",
        "  subDepth = 3\n",
        "  df = \"channels_first\"\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(3, 128, 128))  # Returns a placeholder tensor\n",
        "  if debug_show_shapes: print(\"inputs: {}\".format(inputs.shape))\n",
        "  \n",
        "  l = layers.Conv2D(filters=NF*2, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=tf.nn.relu, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(inputs)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "   \n",
        "  #----\n",
        "  \n",
        "  relu1 = layers.Conv2D(filters=NF*4, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"relu1: {}\".format(relu1.shape))\n",
        "    \n",
        "  #-----------------\n",
        "    \n",
        "  relu2 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(relu1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"relu2: {}\".format(relu2.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  relu3 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(relu2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"relu3: {}\".format(relu3.shape))\n",
        "    \n",
        "  #-----------------\n",
        "\n",
        "  \n",
        "  atrous = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False,\n",
        "                        dilation_rate=2,\n",
        "                        bias_initializer=None)(relu3)\n",
        "  ##INLReLU\n",
        "  if debug_show_shapes: print(\"atrous: {}\".format(atrous.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  atrous2 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False,\n",
        "                        dilation_rate=4,\n",
        "                        bias_initializer=None)(atrous)\n",
        "  ##INLReLU\n",
        "  if debug_show_shapes: print(\"atrous2: {}\".format(atrous2.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  atrous3 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False,\n",
        "                        dilation_rate=8,\n",
        "                        bias_initializer=None)(atrous2)\n",
        "  ##INLReLU\n",
        "  if debug_show_shapes: print(\"atrous3: {}\".format(atrous3.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  merge = tf.concat([relu3, atrous3], axis=1)\n",
        "  if debug_show_shapes: print(\"merge: {}\".format(merge.shape))\n",
        "  #-----------------\n",
        "  \n",
        "  clean = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(merge)\n",
        "  \n",
        "  if debug_show_shapes: print(\"clean: {}\".format(clean.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  lsgan = layers.Conv2D(filters=1, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=tf.identity, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(clean)\n",
        "  \n",
        "  if debug_show_shapes: print(\"lsgan: {}\".format(lsgan.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  model = tf.keras.Model(inputs=inputs, outputs=[lsgan, [relu1, relu2, relu3, atrous, atrous2, atrous3, clean]] )\n",
        "  \n",
        "  if debug_show_shapes: model.summary()\n",
        "\n",
        "  return model  #whats with the other outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qATmfX6bVDMh",
        "colab_type": "code",
        "outputId": "e22e1c85-8390-4842-d046-7022a7742372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "discriminator = Discriminator()\n",
        "\n",
        "noise = tf.random.normal([1, 3, 128, 128])\n",
        "\n",
        "disc_out,a = discriminator([noise, gen_output], training=False)\n",
        "\n",
        "print(disc_out.shape)\n",
        "disc_out = tf.transpose(disc_out, [0, 2, 3, 1])\n",
        "print(disc_out.shape)\n",
        "\n",
        "#plt.imshow(disc_out[0,...])\n",
        "\n",
        "\n",
        "plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "plt.colorbar()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 16, 16)\n",
            "(1, 16, 16, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7ff200317dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAD8CAYAAAAbkUOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGApJREFUeJzt3X+wJWV95/H3Z4YfirICew2MMAha\nxCp0jbK3WA2uSwLBkbVEsiYFuzEYrJqlVnY161YCoWqxNpUqk/gj2dU1XpWAuwRkRQJlUBhIslQs\nIQ4wwgyjMiLizA6MVyxxNyrM3M/+0X2Tc+7Pvqf79Dl97udV1XVP//7S58yX5+mnn35km4iIrtsw\n6gAiIpqQZBYREyHJLCImQpJZREyEJLOImAhJZhExEZLMImJoJG2W9FeSHpG0S9J7yuXHSdom6dHy\n77G1z5XnzCJiWCRtAjbZfkDS0cD9wNuAdwJP2/6ApCuAY23/dp1zpWQWEUNje7/tB8rPPwJ2AycC\nFwDXlZtdR5Hgamm1ZDY1NeWXnnzymvdL2bE+Dbhfrn0zBrn+g1z7J554gtnZ2UG/bgA26/n+CXOV\ntp3l2V3AT3oWzdieWWpbSacA9wCvAp6wfUy5XMAP5ucHdVidndfqpSefzJe//OU175d/UPUlmY1W\nW8nsrLPOGmCvfj9hjn/FpkrbfoLv/MT29GrbSXohcDPwXtvPFPmrYNuSav/UWk1mETH+BGysmn0r\npCBJh1Mksuttf75c/JSkTbb3l/fVDgwSa6/cM4uIPgKO2KBK06rHKopgnwZ22/5wz6rbgEvKz5cA\nt9aNu1Yyk7RF0jck7SlbJCKi44qSmSpNFZwFvAP4RUk7yul84APAL0l6FDi3nK9l4GqmpI3Ax4Bf\nAvYCX5V0m+1H6gYVESOkNVQzV2H7b1j+luE5zZylUOee2ZnAHtuPAUi6kaK5NcksosPmS2ZdU6ea\neSLw3Z75veWyPpK2Stouafv3ZmdrnC4i2jDfAFBlGidDbwCwPWN72vb0i6emhn26iKit2v2ycSu9\n1alm7gM298yfVC6LiA4TcPiYJaoq6iSzrwKnSTqVIoldBPzrRqKKiJHRGFYhqxg4mdk+KOly4A5g\nI3CN7V2NRRYRIzNuVcgqavUAsH07cHtDsUTEGFhTD4Axku5MEdGnq49mtJrMTDouj0oXrvskd4bv\nQozzJCp1VRo3KZlFxCKpZkZE5+WeWURMBDF+D8RWkWQWEYukZBYRnVc8NNu9bJZkFhF95l/O2DVJ\nZhHRJw0AETExUs2MiM6TYEMHk1kGNImIBYQ2VptWPZJ0jaQDknb2LHu/pH0LxgSoLSWziOgjwcYj\nNjZ1uGuBjwKfWbD8I7Y/2NRJIMksIhYSlUpdVdi+pxzJfOhSzYwVqcXJA07RMIkNG6tNNVwu6aGy\nGnpsE2EnmUXEItqwodIETM0PWFROWysc/uPAy4HXAPuBDzURc6qZEdFHYi2lrlnb02s5vu2n/uFc\n+iTwhbXsv5wks4hYpKl7ZkseW9pke385eyGwc6Xtq6ozovlmihaK4yluXczY/uMmgoqI0ZHUWGum\npBuAsymqo3uBq4GzJb2GIm88DvzbJs5Vp2R2EHif7QckHQ3cL2mb7YxoHtFlAjXUN9P2xUss/nQj\nB1+gzuhM+ylu3mH7R5J2U4xonmQW0Wliw8butQ02cs+sfI7ktcB9S6zbCmwF2Lx588LVETFuGnzO\nrE2106+kFwI3A++1/czC9bZnbE/bnp6amqp7uogYMpXJrInuTG2qVTKTdDhFIrve9uebCSkiRm1d\nVTMlieJG3m7bH24upIgYJUlsPHwdJTPgLOAdwMOSdpTLfqcc5Twiukqg9VQys/03DD5ua0SMsZr9\nLkciPQAiop/G7+Z+FUlmCwzyFebNDYvlmtQ3yG+xiRSk9VbNjIgJJdZdA0BETCCt5x4AETFBOtoD\nIMksIvrlnllETAbNv0W2U5LMIqJP8abZJLOI6DqJDUd0LzV0L+KIGLJUMyNiEgi0sbFBgFuTZBYR\nfYQ62ZrZvYgjYrgEGzZsqDSteqhikN8Dknb2LDtO0jZJj5Z/MwhwRAyHNm6oNFVwLbBlwbIrgLtt\nnwbcXc7XlmrmAukg3S/Xo9+gz8UPch3b2mchSWw4vJnUYPuecoyQXhdQDD8HcB3w18Bv1z1XkllE\n9NOa7plNSdreMz9je2aVfY7vGQT4SYqxd2tLMouIfmvrzjRre3rQU9m2pEYqAElmEbHIkHsAPCVp\nk+39kjYBB5o4aBNDzW2U9KCkLzQRUESMllQ8NFtlGtBtwCXl50uAW5uIu4mS2XuA3cA/auBYETFq\nDXZnknQDxc3+KUl7gauBDwA3SXoX8B3gV5s4V91xM08C/iXwe8B/bCKgiBi9proz2b54mVXnNHKC\nHnXT7x8BvwUc3UAsETEGJLGhg92ZBk6/kt4CHLB9/yrbbZW0XdL22dnZQU8XES1q8KHZ1tSJ5izg\nrZIeB24EflHS/1y4ke0Z29O2p6empmqcLiJaoXWWzGxfafsk26cAFwF/afvXGossIkZk6K2ZQ5Hn\nzCKijzas45cz2v5riv5VETEBxq3UVUX30m9EDJeENnSvNTPJLGIN1s1bRJLMIqL7BKlmRkTnZQyA\niJgIEhx2xKijWLMks4jooww1FxETQaQBICImgZLMImIypJoZEd2nDWkAiIgJkEczImIy5KHZiJgE\nDbdmlu88/BFwCDhYZ2i6lSSZRcQCQ+lo/gu2h/qq6SSziFgs1czu06gDqGDdvLkhRkMbUPXWzClJ\n23vmZ2zPLNjGwJ3lyOWfWGJ9I5LMIqKfWEvJbLbCPbA32N4n6WeAbZK+bvueWjEuoXtlyYgYKiG0\ncWOlqQrb+8q/B4BbgDOHEXeSWUT0m2/NrDKtdijpBZKOnv8MnAfsHEbYdUc0Pwb4FPAqinrxpba/\n0kRgETEqjfbNPB64RRIU+ebPbH+pqYP3qnvP7I+BL9l+u6QjgKMaiCkiRklChx3eyKFsPwb8XCMH\nW8XAyUzSi4A3Au8EsP0s8GwzYUXESKl7d6DqRHwq8D3gTyU9KOlTZZ24j6StkrZL2j47O9Rn5iKi\nESqSWZVpjNSJ5jDgDODjtl8L/D/gioUb2Z6xPW17empqqsbpIqIt1oZK0zipE81eYK/t+8r5z1Ek\nt4joMrG+Sma2nwS+K+kV5aJzgEcaiSoiRkjFoCZVpjFStzXz3wPXly2ZjwG/UT+kiBglA97Yvc5B\ntSK2vQMYyus8ImJEpLGrQlbRavoVg3XkbrNjdTpx9xu0ItHmdRz331QnJZlFRPelZBYRE2LcHruo\nIsksIhZLMouIzlMGAY6ICZFqZkRMgAw1FxGTYL47U8ckmUXEAnk0IyImhDd0LzV0L+KIGK6Odmfq\nXsQRMXwNvjVD0hZJ35C0R9Kidx42JcksIhZo7k2zkjYCHwPeDJwOXCzp9GFEnWQWEYs0+KbZM4E9\nth8rxwm5EbhgGDG3es/MtPe2gi687aELunA9uhBj51S/ZzYlaXvP/IztmZ75E4Hv9szvBf5ZzeiW\nlAaAiOhjxFz14sCs7bF4p2GSWUQsYObcWHl3H7C5Z/6kclnjcs8sIhZxxamCrwKnSTq1fL3+RcBt\nzUdcM5lJ+k1JuyTtlHSDpOc1FVhEjIaBOVebVj2WfRC4HLgD2A3cZHvXMOKuM6L5icB/AE63/WNJ\nN1Fk3Wsbii0iRsTNVTOxfTtwe2MHXEbde2aHAc+X9BxwFPB/6ocUEaM0XzLrmjrjZu4DPgg8AewH\nfmj7zoXbSdoqabuk7bOzs4NHGhHtMByqOI2TgZOZpGMpHn47FXgJ8AJJv7ZwO9sztqdtT09NTQ0e\naUS0xnalaZzUaQA4F/i27e/Zfg74PPDzzYQVEaNiYK7iNE7q3DN7AnidpKOAHwPnANtX3iUiumDM\nCl2VDJzMbN8n6XPAA8BB4EFgZuW9IqILutgAUKs10/bVwNUNxRIRY8CGQx0smqU7U0Qs0sFcNrnJ\nrM3vou03dAx6vkG0GWMX/v2sh7exFM+ZdSniwsQms4gYXPdSWZJZRCxh3TUARMRk6mAtM8ksIvrZ\nTmtmREyGVDMjovNMqpkRMSHmOtiemWQWEYukZBYRndfVh2YzoElE9LHhuUOuNNUh6f2S9knaUU7n\n1zleSmYRsUCrj2Z8xPYHmzhQkllE9OlqNTPJrAFtf+2T3Ik+xoDhUPXXyE5J6n0p64zttbzX8HJJ\nv07xYtf32f7BGvbtk2QWEX3WWDKbtT293EpJdwEnLLHqKuDjwO+Wp/xd4EPApWsKtkeSWUT0MfBc\nQ10AbJ9bZTtJnwS+UOdcSWYR0c9wqIX+TJI22d5fzl4I7KxzvFUfzZB0jaQDknb2LDtO0jZJj5Z/\nj60TRESMD2PmXG2q6Q8kPSzpIeAXgN+sc7Aqz5ldC2xZsOwK4G7bpwF3l/MRMSHaGATY9jts/xPb\nr7b91p5S2kBWTWa27wGeXrD4AuC68vN1wNvqBBER42O+AaCFklmjBr1ndnxPFn0SOH65DSVtBbYC\nbN68ecDTRURrWrpn1rTa3ZlcjNG+7H+57Rnb07anp6am6p4uIoZsvjWzyjROBi2ZPTXfEiFpE3Cg\nyaAiYnS62gNg0JLZbcAl5edLgFubCSciRs5mbq7aNE5WLZlJugE4m6Lbwl6KEcw/ANwk6V3Ad4Bf\nHWaQEdEeU7+lchRWTWa2L15m1TkNxxIRY6KL1cz0AIiIPsX7zKr3NB8XSWaxou79/7matt8GMuj5\nRnGeia1mRsT6k2pmRHSe233TbGOSzCKiX0d7ACSZRUQfk2QWERPAhmcPpjUzIjrOOCWziJgAuWcW\nEZMg98wiYiK4oyWz2u8zi4jJc2jOlaY6JP2KpF2S5iRNL1h3paQ9kr4h6U1VjpeSWUT0mbP5aTut\nmTuBXwY+0btQ0unARcArgZcAd0n6WduHVjpYkllELNJGNdP2bgBpUY/SC4Abbf8U+LakPcCZwFdW\nOl6SWayorQ7S0G4n7rY7jA9yvjavfa813jObkrS9Z37G9kzNEE4E7u2Z31suW1GSWUQssoa+mbO2\np5dbKeku4IQlVl1lu9E3VCeZRUSfJh+atX3uALvtA3qHcjupXLaiJLOI6DMG3ZluA/5M0ocpGgBO\nA/52tZ1WfTRD0jWSDkja2bPsDyV9XdJDkm6RdEydyCNifBQPzc5VmuqQdGE5rsjrgb+QdAeA7V3A\nTcAjwJeAd6/WkgnVnjO7FtiyYNk24FW2Xw18E7iy8n9BRIw3V3vGrG5V1PYttk+yfaTt422/qWfd\n79l+ue1X2P5ileOtmsxs3wM8vWDZnbYPlrP3UtRpI2ICzHdnGnYya1oT98wuBT673EpJW4GtAJs3\nb15us4gYEzYcHLNEVUWt7kySrgIOAtcvt43tGdvTtqenpqbqnC4iWrDuSmaS3gm8BTjH7uALwyNi\nSbZH3Zo5kIGSmaQtwG8B/8L23zUbUkSM2riVuqpYNZlJugE4m6Lbwl7gaorWyyOBbWW/qnttXzbE\nOCOiJV19BdCqycz2xUss/vQQYomIMeFJTGYRsb7YMJdk1n1tvoFhUG3G2IWfdJsxjvu5GupRSRfb\n9JLMIqKf4dB6ac2MiMllwN3LZUlmEbFYqpkR0X1pAIiIyeA8mhER3WfDoUPdu2mWZBYRi6RkFhET\nIcksIjrPdicbAGq9zywiJpPtSlMdkn5F0i5Jc5Kme5afIunHknaU059UOV5KZhGxSEsPze4Efhn4\nxBLrvmX7NWs5WJJZRPRxS92ZbO8GKF8jVluqmRHRz0UDQJVpiE6V9KCk/y3pn1fZISWzBbpw27ML\nMU6qQcsQ3frOzFz1+2FTkrb3zM/YnpmfkXQXcMIS+11l+9ZljrkfONn29yX9U+DPJb3S9jMrBZJk\nFhF9io7mlZPZrO3p5VbaPnfN57d/Cvy0/Hy/pG8BPwtsX2m/JLOI6OfRPmcm6cXA07YPSXoZcBrw\n2Gr7rXrPTNI1kg5I2rnEuvdJsqSMIRcxQebmXGmqQ9KF5bgirwf+QtId5ao3Ag9J2gF8DrjM9tPL\nHWdelZLZtcBHgc8sCGQzcB7wRPXwI2Lc2Wauhb6Ztm8Bblli+c3AzWs93qolM9v3AEtlxY9QDDfX\nrXubEbGqNkpmTRt03MwLgH22v7baMyKStgJbATZv3jzI6SKiZZ47NOoQ1mzNyUzSUcDvUFQxV1U2\n084AnHHGGeOVyiNiMXt9JDPg5cCpwHyp7CTgAUln2n6yyeAion1mnSQz2w8DPzM/L+lxYNr2bINx\nRcSo2Mw99+yoo1izKo9m3AB8BXiFpL2S3jX8sCJiZMpqZpVpnKxaMrN98SrrT2ksmogYC+OWqKpI\nD4CI6LNu7pnVIQbrqDtIE2ibHYInufNxMy9nGa42r+Og52rrOjZyHqdkFhETwcwlmUVE19lm7mD3\nWjOTzCKin40PpWQWERMg98wiovvWUXemiJhoSWYRMQGK12a3M9Zck5LMIqJfWjMjYiI4z5lFxAQw\ndPLRjAwCHBH9WnprhqQ/lPR1SQ9JukXSMT3rrpS0R9I3JL2pyvGSzCJigdZeAbQNeJXtVwPfBK4E\nkHQ6cBHwSmAL8N8lbVztYKlmRkS/lhoAbN/ZM3sv8Pby8wXAjeVgwN+WtAc4k+K9istqNZk98OCD\ns88/6qjvLLN6ChiHt9Umjn6Jo9+4x/HSugf2j79/x3M7/rTqWLjPk9Q70vhMOe7HWl0KfLb8fCJF\ncpu3t1y2olaTme0XL7dO0vaVhnlvS+JIHOs9DttbmjqWpLuAE5ZYdZXtW8ttrgIOAtfXOVeqmREx\nNLbPXWm9pHcCbwHOsT3/urh9QO+4lCeVy1aUBoCIGAlJWygGEn+r7b/rWXUbcJGkIyWdCpwG/O1q\nxxunktkg9exhSBz9Eke/xNGcjwJHAtvKYSvvtX2Z7V2SbgIeoah+vtv2qk2n+oeSXUREd6WaGRET\nIcksIiZCq8lM0paye8IeSVcssf5ISZ8t198n6ZQhxLBZ0l9JekTSLknvWWKbsyX9UNKOcvrPTcfR\nc67HJT1cnmf7Eusl6b+W1+QhSWc0fP5X9Px37pD0jKT3LthmaNdD0jWSDkja2bPsOEnbJD1a/j12\nmX0vKbd5VNIlQ4hj2e42C/Zd8TtsII73S9rXc/3PX2bfFf99TTzbrUzARuBbwMuAI4CvAacv2Obf\nAX9Sfr4I+OwQ4tgEnFF+PpqiG8XCOM4GvtDSdXkcmFph/fnAFylGEXsdcN+Qv6MngZe2dT2ANwJn\nADt7lv0BcEX5+Qrg95fY7zjgsfLvseXnYxuO4zzgsPLz7y8VR5XvsIE43g/8pwrf3Yr/viZ9arNk\ndiawx/Zjtp8FbqTottDrAuC68vPngHNUNnM0xfZ+2w+Un38E7KbC08UjdAHwGRfuBY6RtGlI5zoH\n+Jbt5XppNM72PcDTCxb3/g6uA962xK5vArbZftr2Dyj6+Q38sOdScdi+0/bBcvZeiuedhmqZ61FF\nlX9fE63NZHYi8N2e+aW6KPz9NuWP6IfAPx5WQGU19rXAfUusfr2kr0n6oqRXDisGijeu3Cnpfklb\nl1hf5bo15SLghmXWtXU9AI63vb/8/CRw/BLbtHldoOhu88Vl1q32HTbh8rK6e80y1e62r8fYWbcN\nAJJeCNwMvNf2MwtWP0BR1fo54L8Bfz7EUN5g+wzgzcC7Jb1xiOdalqQjgLcC/2uJ1W1ejz4u6lAj\nfX6oQnebYX+HHwdeDrwG2A98qOHjT4Q2k1mVLgp/v42kw4AXAd9vOhBJh1Mksuttf37hetvP2P6/\n5efbgcMlVe14uya295V/DwC3UFQXeg3UtWMAbwYesP3UEjG2dj1KT81Xpcu/B5bYppXr0tPd5t+U\niXWRCt9hLbafsn3I9hzwyWWO39bvZGy1mcy+Cpwm6dSyFHARRbeFXrcB861Sbwf+crkf0KDKe3Cf\nBnbb/vAy25wwf69O0pkU12kYSfUFko6e/0xxw3nngs1uA369bNV8HfDDnipYky5mmSpmW9ejR+/v\n4BLg1iW2uQM4T9KxZbXrvHJZY7R8d5vebap8h3Xj6L1HeuEyx6/y72uytdnaQNEy902KVperymX/\nheLHAvA8imrOHoq+WC8bQgxvoKi2PATsKKfzgcuAy8ptLgd2UbQI3Qv8/JCux8vKc3ytPN/8NemN\nRcDHymv2MDA9hDheQJGcXtSzrJXrQZFA9wPPUdzneRfFfdK7gUeBu4Djym2ngU/17Htp+VvZA/zG\nEOLYQ3Efav53Mt/S/hLg9pW+w4bj+B/ld/8QRYLatDCO5f59racp3ZkiYiKs2waAiJgsSWYRMRGS\nzCJiIiSZRcRESDKLiImQZBYREyHJLCImwv8HIZ6JsNmd0icAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLxMw-xvK4Je",
        "colab_type": "text"
      },
      "source": [
        "# losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_NCxP-CGYVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_match_loss(feats_real, feats_fake):\n",
        "  print(\"gfml-1\")\n",
        "  #print(feats_fake)\n",
        "  losses = []\n",
        "  for real, fake in zip(feats_real, feats_fake):\n",
        "      loss = tf.reduce_mean(tf.math.squared_difference(\n",
        "          tf.reduce_mean(real, 0),\n",
        "          tf.reduce_mean(fake, 0)),\n",
        "          name='mse_feat_' + real.op.name)\n",
        "      losses.append(loss)\n",
        "  ret = tf.reduce_mean(losses, name='feature_match_loss')\n",
        "  #add_moving_summary(ret)\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyHxPp0vGiCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_normalize(loss, update_condition, epsilon=1e-10):\n",
        "  print(\"loss-norm1:{}\".format(loss))\n",
        "  print(\"loss-norm2:{}\".format(update_condition))\n",
        "  \n",
        "  # Variable used for storing the scalar-value of the loss-function.\n",
        "  loss_value = tf.Variable(1.0, name='loss_scalar_val_' + loss.op.name,\n",
        "          trainable=False)\n",
        "\n",
        "  loss_value_smooth = (tf.Variable(1.0, name='loss_smooth_' +\n",
        "          loss.op.name, trainable=False))\n",
        "\n",
        "  #TODO don't update if is_training\n",
        "  ma_loss_value = (\n",
        "      moving_averages.assign_moving_average(\n",
        "              loss_value_smooth, loss, 0.9999, zero_debias=False, name='loss_EMA'\n",
        "          )\n",
        "      )\n",
        "\n",
        "  #tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, ma_loss_value)\n",
        "  # Expression used for either updating the scalar-value or\n",
        "  # just re-using the old value.\n",
        "  # Note that when loss_value.assign(loss) is evaluated, it\n",
        "  # first evaluates the loss-function which is a TensorFlow\n",
        "  # expression, and then assigns the resulting scalar-value to\n",
        "  # the loss_value variable.\n",
        "  print(\"upd-cond:{}\".format(update_condition))\n",
        "  print(\"ma-loss:{}\".format(ma_loss_value))\n",
        "  print(\"loss-val:{}\".format(loss_value))\n",
        "  loss_value_updated = tf.cond(update_condition,\n",
        "                               lambda: loss_value.assign(ma_loss_value),\n",
        "                               lambda: loss_value)\n",
        "\n",
        "\n",
        "  print(\"loss-upd\")\n",
        "  # Expression for the normalized loss-function.\n",
        "  loss_normalized = loss / (loss_value_updated + epsilon)\n",
        "  print(\"loss-upd-1\")\n",
        "  #add_moving_summary(tf.identity(loss_value, name='loss_scalar_' + loss.op.name))\n",
        "\n",
        "  return loss_normalized\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEUBZUZrRLg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _tf_fspecial_gauss(size, sigma):\n",
        "  \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "  \"\"\"\n",
        "  x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "\n",
        "  x_data = np.expand_dims(x_data, axis=-1)\n",
        "  x_data = np.expand_dims(x_data, axis=-1)\n",
        "\n",
        "  y_data = np.expand_dims(y_data, axis=-1)\n",
        "  y_data = np.expand_dims(y_data, axis=-1)\n",
        "\n",
        "  x = tf.constant(x_data, dtype=tf.float32)\n",
        "  y = tf.constant(y_data, dtype=tf.float32)\n",
        "\n",
        "  g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
        "  return g / tf.reduce_sum(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KXiarnhREpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_ssim(img1, img2, cs_map=False, mean_metric=True, size=8, sigma=1.5):\n",
        "  window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
        "  K1 = 0.03\n",
        "  K2 = 0.05\n",
        "  L = 1  # depth of image (255 in case the image has a differnt scale)\n",
        "  C1 = (K1*L)**2\n",
        "  C2 = (K2*L)**2\n",
        "  mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
        "  mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1], padding='VALID')\n",
        "  mu1_sq = mu1*mu1\n",
        "  mu2_sq = mu2*mu2\n",
        "  mu1_mu2 = mu1*mu2\n",
        "  sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
        "  sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
        "  sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
        "  sigma1_sq = tf.abs(sigma1_sq)\n",
        "  sigma2_sq = tf.abs(sigma2_sq)\n",
        "  sigma12 = tf.abs(sigma12)\n",
        "  if cs_map:\n",
        "\n",
        "      value = (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                  (sigma1_sq + sigma2_sq + C2)),\n",
        "              (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
        "  else:\n",
        "      value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                  (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "  if mean_metric:\n",
        "      value = tf.reduce_mean(value)\n",
        "  return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M2b0P0kQ9i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_ms_ssim(img1, img2, mean_metric=True, level=5):\n",
        "  #From NCHW to NHWC\n",
        "  img1 = tf.transpose(img1, [0, 2, 3, 1])\n",
        "  img2 = tf.transpose(img2, [0, 2, 3, 1])\n",
        "\n",
        "  weight = tf.constant([0.0448, 0.2856, 0.3001, 0.2363, 0.1333], dtype=tf.float32)\n",
        "  mssim = []\n",
        "  mcs = []\n",
        "  for l in range(level):\n",
        "      ssim_map, cs_map = tf_ssim(img1, img2, cs_map=True, mean_metric=False)\n",
        "      mssim.append(tf.reduce_mean(ssim_map))\n",
        "      mcs.append(tf.reduce_mean(cs_map))\n",
        "      filtered_im1 = tf.nn.avg_pool(img1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "      filtered_im2 = tf.nn.avg_pool(img2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "      img1 = filtered_im1\n",
        "      img2 = filtered_im2\n",
        "\n",
        "  # list to tensor of dim D+1\n",
        "  mssim = tf.stack(mssim, axis=0)\n",
        "  mcs = tf.stack(mcs, axis=0)\n",
        "\n",
        "  value = (tf.reduce_prod(mcs[0:level-1]**weight[0:level-1])*\n",
        "                          (mssim[level-1]**weight[level-1]))\n",
        "\n",
        "  if mean_metric:\n",
        "      value = tf.reduce_mean(value)\n",
        "  return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF5iWLVAQrh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_dssim(img1, img2):\n",
        "  img1 = tf.unstack(tf.expand_dims(img1, axis=2), axis=1)\n",
        "  img2 = tf.unstack(tf.expand_dims(img2, axis=2), axis=1)\n",
        "  value = tf.stack([tf_ms_ssim(i1, i2) for i1, i2 in zip(img1, img2)], axis=0)\n",
        "  return tf.subtract(1.0, tf.reduce_sum(value)/3, name='DSSIM_loss')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErsvNLhPTGqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_losses(logits_real, logits_fake):\n",
        "  #Build standard GAN loss and set `self.g_loss` and `self.d_loss`.\n",
        "  #D and G play two-player minimax game with value function V(G,D)\n",
        "  #  min_G max _D V(D, G) = IE_{x ~ p_data} [log D(x)] + IE_{z ~ p_fake} [log (1 - D(G(z)))]\n",
        "  #Args:\n",
        "  #    logits_real (tf.Tensor): discrim logits from real samples\n",
        "  #    logits_fake (tf.Tensor): discrim logits from fake samples produced by generator\n",
        "\n",
        "  with tf.name_scope(\"GAN_loss\"):\n",
        "    score_real = tf.sigmoid(logits_real)\n",
        "    score_fake = tf.sigmoid(logits_fake)\n",
        "    #tf.summary.histogram('score-real', score_real)\n",
        "    #tf.summary.histogram('score-fake', score_fake)\n",
        "\n",
        "    with tf.name_scope(\"discrim\"):\n",
        "        d_loss_pos = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=logits_real, labels=tf.ones_like(logits_real)), name='loss_real')\n",
        "        d_loss_neg = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=logits_fake, labels=tf.zeros_like(logits_fake)), name='loss_fake')\n",
        "\n",
        "        d_pos_acc = tf.reduce_mean(tf.cast(score_real > 0.5, tf.float32), name='accuracy_real')\n",
        "        d_neg_acc = tf.reduce_mean(tf.cast(score_fake < 0.5, tf.float32), name='accuracy_fake')\n",
        "\n",
        "        d_accuracy = tf.add(.5 * d_pos_acc, .5 * d_neg_acc, name='accuracy')\n",
        "        d_loss = tf.add(.5 * d_loss_pos, .5 * d_loss_neg, name='loss')\n",
        "\n",
        "    with tf.name_scope(\"gen\"):\n",
        "        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=logits_fake, labels=tf.ones_like(logits_fake)), name='loss')\n",
        "        g_accuracy = tf.reduce_mean(tf.cast(score_fake > 0.5, tf.float32), name='accuracy')\n",
        "\n",
        "    #add_moving_summary(g_loss, d_loss, d_accuracy, g_accuracy)\n",
        "    \n",
        "    return g_loss, d_loss, d_accuracy, g_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpT89fEdmnHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  d_loss = tf.add(D_loss_A, D_loss_B, name='D_loss_total')\n",
        "  \n",
        "  return d_loss\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KepfzD6nm2xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(A, ABA, B, BAB, A_dis_real, A_feats_real,\n",
        "                                   A_dis_fake, A_feats_fake,\n",
        "                                   B_dis_real, B_feats_real,\n",
        "                                   B_dis_fake, B_feats_fake):\n",
        "  \n",
        "  recon_loss_A = tf_dssim(A, ABA)\n",
        "  if print_debug: print(\"recon_loss_A-shape: {}\".format(recon_loss_A.shape))\n",
        "  if print_debug: print(\"A-shape: {}\".format(A.shape))\n",
        "  if print_debug: print(\"ABA-shape: {}\".format(ABA.shape))\n",
        "  recon_loss_A_l = tf.compat.v1.losses.absolute_difference(A,\n",
        "                                            ABA,\n",
        "                                            reduction=tf.compat.v1.losses.Reduction.MEAN)\n",
        "  if print_debug: print(\"recon_loss_A_l-shape: {}\".format(recon_loss_A_l.shape))\n",
        "\n",
        "  # gan loss\n",
        "  g_loss, d_loss, d_accuracy, g_accuracy = build_losses(A_dis_real, A_dis_fake)\n",
        "  G_loss_A = g_loss\n",
        "  D_loss_A = d_loss\n",
        "  # feature matching loss\n",
        "  if print_debug: print(A_feats_fake)\n",
        "  fm_loss_A = get_feature_match_loss(A_feats_real, A_feats_fake)\n",
        "  #-------------------\n",
        "\n",
        "  recon_loss_B = tf_dssim(B, BAB)\n",
        "  if print_debug: print(\"recon_loss_B-shape: {}\".format(recon_loss_B.shape))\n",
        "\n",
        "  recon_loss_B_l = tf.compat.v1.losses.absolute_difference(B,\n",
        "                                            BAB,\n",
        "                                            reduction=tf.compat.v1.losses.Reduction.MEAN)\n",
        "  if print_debug: print(\"recon_loss_B_l-shape: {}\".format(recon_loss_B_l.shape))\n",
        "\n",
        "  g_loss, d_loss, d_accuracy, g_accuracy = build_losses(B_dis_real, B_dis_fake)\n",
        "  G_loss_B = g_loss\n",
        "  D_loss_B = d_loss# + grad_penalty_B\n",
        "  fm_loss_B = get_feature_match_loss(B_feats_real, B_feats_fake)\n",
        "  #-------------------\n",
        "\n",
        "  global_step = np.int64(1)   #get_global_step_var()\n",
        "  rate = 0.01  #tf.train.piecewise_constant(global_step, [np.int64(15000), np.int64(25000), np.int64(50000), np.int64(100000)], [0.01, 0.10, 0.15, 0.20, 0.25])\n",
        "  #rate = tf.identity(rate, name='rate')   # mitigate a TF bug\n",
        "  loss_update = tf.logical_or(tf.equal(global_step, tf.constant(36,\n",
        "      dtype=np.int64)), tf.equal(global_step % 90, tf.constant(0, dtype=np.int64)))\n",
        "  rate = tf.constant(0.33, np.float32, name='static_rate')\n",
        "\n",
        "\n",
        "  g_loss = tf.add_n([\n",
        "      (loss_normalize(G_loss_A + G_loss_B, loss_update) * 0.7 +\n",
        "      loss_normalize(fm_loss_A + fm_loss_B, loss_update) * 0.3) * (1 - rate),\n",
        "      (loss_normalize((recon_loss_A + recon_loss_B), loss_update) *\n",
        "          0.7 +\n",
        "  loss_normalize((recon_loss_A_l + recon_loss_B_l),\n",
        "              loss_update) * 0.3) * rate], name='G_loss_total')\n",
        "\n",
        "\n",
        "  d_loss = tf.add(D_loss_A, D_loss_B, name='D_loss_total')\n",
        "\n",
        "  #@TODO what todo? collect_variables('gen', 'discrim')\n",
        "\n",
        "  g_loss = g_loss\n",
        "  d_loss = d_loss \n",
        "\n",
        "  \n",
        "  return g_loss, d_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-9Z01QLVjF",
        "colab_type": "text"
      },
      "source": [
        "# optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk036iXixrHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lr = tf.get_variable('learning_rate', initializer=2e-4,\n",
        "#                 trainable=False)\n",
        "#        return tf.train.AdamOptimizer(lr, beta1=0.5)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwHsakYaLhz9",
        "colab_type": "text"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKNKgCD5Vzey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_variables(self, g_scope='gen', d_scope='discrim'):\n",
        "  #\"\"\"\n",
        "  #Assign `self.g_vars` to the parameters under scope `g_scope`,\n",
        "  #and same with `self.d_vars`.\n",
        "  #\"\"\"\n",
        "  self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, g_scope)\n",
        "  assert self.g_vars\n",
        "  self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, d_scope)\n",
        "  assert self.d_vars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQatM82Ty-EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A = tf.Variable(1.0)\n",
        "#AB = tf.Variable([3, 128, 128])\n",
        "#AB = None\n",
        "#BA = None\n",
        "#ABA = None\n",
        "#BAB = None\n",
        "\n",
        "print_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdQWnkOGx4gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(A, B):\n",
        "#  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "#    gen_output = generator(input_image, training=True)\n",
        "#\n",
        "#    disc_real_output = discriminator([input_image, target], training=True)\n",
        "#    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "#\n",
        "#    gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "#    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "#  generator_gradients = gen_tape.gradient(gen_loss,\n",
        "#                                          generator.trainable_variables)\n",
        "#  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "#                                               discriminator.trainable_variables)\n",
        "\n",
        "#  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "#                                          generator.trainable_variables))\n",
        "#  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "#                                              discriminator.trainable_variables))\n",
        "  \n",
        "  \n",
        "  if print_debug: print(\"train step\")\n",
        "  \n",
        "  print(\"train\")\n",
        "\n",
        "  \n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    AB = generator(A, training=True)\n",
        "    BA = generator(B, training=True)\n",
        "    ABA = generator(AB, training=True)\n",
        "    BAB = generator(BA, training=True)\n",
        "    if print_debug: print(\"BAB\")\n",
        "    \n",
        "    A_dis_real, A_feats_real = discriminator(A, training=True)\n",
        "    A_dis_fake, A_feats_fake = discriminator(BA, training=True)\n",
        "    B_dis_real, B_feats_real = discriminator(B, training=True)\n",
        "    B_dis_fake, B_feats_fake = discriminator(AB, training=True)\n",
        "  \n",
        "    #------------\n",
        "    g_loss, d_loss = generator_loss(A, ABA, B, BAB, A_dis_real, A_feats_real,\n",
        "                                   A_dis_fake, A_feats_fake,\n",
        "                                   B_dis_real, B_feats_real,\n",
        "                                   B_dis_fake, B_feats_fake)\n",
        "      \n",
        "      \n",
        "    \n",
        "    if print_debug: print(\"end train step\")\n",
        "    \n",
        "    #add_moving_summary(recon_loss_A, recon_loss_B, rate, g_loss, d_loss,\n",
        "    #        recon_loss_A_l, recon_loss_B_l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbP4P_KFxtph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM0iKglUyVOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for input_image, target in dataset:\n",
        "      print(\"loop\")\n",
        "      train_step(input_image, target)\n",
        "      print(\"loop1\")\n",
        "\n",
        "    print(\"after loop1-------------\")  \n",
        "    clear_output(wait=True)\n",
        "    #for inp, tar in image_ds_testA_B.take(1):\n",
        "    #  generate_images(generator, inp, tar)\n",
        "\n",
        "    # saving (checkpoint) the model every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngXLySdSydzQ",
        "colab_type": "code",
        "outputId": "9dc54b3b-5204-40cc-9fd7-4460ec03b29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        }
      },
      "source": [
        "EPOCHS = 2\n",
        "print(image_ds_trainA_B)\n",
        "\n",
        "dst = image_ds_trainA_B.take(3)\n",
        "\n",
        "train(dst, EPOCHS)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 3, 128, 128), (None, 3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "loop\n",
            "train step\n",
            "train\n",
            "BAB\n",
            "recon_loss_A-shape: ()\n",
            "A-shape: (2, 3, 128, 128)\n",
            "ABA-shape: (2, 3, 128, 128)\n",
            "recon_loss_A_l-shape: ()\n",
            "[<tf.Tensor 'model_1_2/conv2d_50/re_lu_31/Relu:0' shape=(2, 256, 32, 32) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_51/re_lu_32/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_52/re_lu_33/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_53/re_lu_34/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_54/re_lu_35/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_55/re_lu_36/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_56/re_lu_37/Relu:0' shape=(2, 512, 16, 16) dtype=float32>]\n",
            "gfml-1\n",
            "recon_loss_B-shape: ()\n",
            "recon_loss_B_l-shape: ()\n",
            "gfml-1\n",
            "loss-norm1:Tensor(\"add_300:0\", shape=(), dtype=float32)\n",
            "loss-norm2:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "upd-cond:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "ma-loss:<tf.Variable 'UnreadVariable' shape=() dtype=float32>\n",
            "loss-val:<tf.Variable 'loss_scalar_val_add_300:0' shape=() dtype=float32>\n",
            "loss-upd\n",
            "loss-upd-1\n",
            "loss-norm1:Tensor(\"add_302:0\", shape=(), dtype=float32)\n",
            "loss-norm2:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "upd-cond:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "ma-loss:<tf.Variable 'UnreadVariable' shape=() dtype=float32>\n",
            "loss-val:<tf.Variable 'loss_scalar_val_add_302:0' shape=() dtype=float32>\n",
            "loss-upd\n",
            "loss-upd-1\n",
            "loss-norm1:Tensor(\"add_305:0\", shape=(), dtype=float32)\n",
            "loss-norm2:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "upd-cond:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "ma-loss:<tf.Variable 'UnreadVariable' shape=() dtype=float32>\n",
            "loss-val:<tf.Variable 'loss_scalar_val_add_305:0' shape=() dtype=float32>\n",
            "loss-upd\n",
            "loss-upd-1\n",
            "loss-norm1:Tensor(\"add_307:0\", shape=(), dtype=float32)\n",
            "loss-norm2:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "upd-cond:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n",
            "ma-loss:<tf.Variable 'UnreadVariable' shape=() dtype=float32>\n",
            "loss-val:<tf.Variable 'loss_scalar_val_add_307:0' shape=() dtype=float32>\n",
            "loss-upd\n",
            "loss-upd-1\n",
            "end train step\n",
            "train step\n",
            "train\n",
            "BAB\n",
            "recon_loss_A-shape: ()\n",
            "A-shape: (2, 3, 128, 128)\n",
            "ABA-shape: (2, 3, 128, 128)\n",
            "recon_loss_A_l-shape: ()\n",
            "[<tf.Tensor 'model_1_2/conv2d_50/re_lu_31/Relu:0' shape=(2, 256, 32, 32) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_51/re_lu_32/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_52/re_lu_33/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_53/re_lu_34/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_54/re_lu_35/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_55/re_lu_36/Relu:0' shape=(2, 512, 16, 16) dtype=float32>, <tf.Tensor 'model_1_2/conv2d_56/re_lu_37/Relu:0' shape=(2, 512, 16, 16) dtype=float32>]\n",
            "gfml-1\n",
            "recon_loss_B-shape: ()\n",
            "recon_loss_B_l-shape: ()\n",
            "gfml-1\n",
            "loss-norm1:Tensor(\"add_300:0\", shape=(), dtype=float32)\n",
            "loss-norm2:Tensor(\"LogicalOr:0\", shape=(), dtype=bool)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-2ea0f2ae24f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_ds_trainA_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-6836f9337c3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loop1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_canonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1578\u001b[0m           or call_context_key not in self._function_cache.missed):\n\u001b[1;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1513\u001b[0m         self._function_attributes)\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    692\u001b[0m                                           converted_func)\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, IndexedSlices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                   \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                   \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m               ), args, kwargs)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Wrapping around a decorator allows checks like tf_inspect.getargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/tmph3jt7hmq.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mB_dis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_feats_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mB_dis_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_feats_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBAB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_dis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_feats_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_dis_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_feats_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_dis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_feats_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_dis_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_feats_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mcond_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/tmpfay80j1_.py\u001b[0m in \u001b[0;36mtf__generator_loss\u001b[0;34m(A, ABA, B, BAB, A_dis_real, A_feats_real, A_dis_fake, A_feats_fake, B_dis_real, B_feats_real, B_dis_fake, B_feats_fake)\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0mloss_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logical_or'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[...\n\u001b[1;32m     83\u001b[0m   \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'static_rate'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add_n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_loss_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mG_loss_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_update\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.7\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm_loss_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfm_loss_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_update\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrate\u001b...\n\u001b[0m\u001b[1;32m     85\u001b[0m   \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD_loss_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_loss_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'D_loss_total'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-61f53da421a6>\u001b[0m in \u001b[0;36mloss_normalize\u001b[0;34m(loss, update_condition, epsilon)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Variable used for storing the scalar-value of the loss-function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   loss_value = tf.Variable(1.0, name='loss_scalar_val_' + loss.op.name,\n\u001b[0;32m----> 7\u001b[0;31m           trainable=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   loss_value_smooth = (tf.Variable(1.0, name='loss_smooth_' +\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;34m\"\"\"To avoid capturing loop variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36minvalid_creator_scope\u001b[0;34m(*unused_args, **unused_kwds)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;34m\"\"\"Disables variable creation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       raise ValueError(\n\u001b[0;32m--> 375\u001b[0;31m           \u001b[0;34m\"tf.function-decorated function tried to create \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m           \"variables on non-first call.\")\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.function-decorated function tried to create variables on non-first call."
          ]
        }
      ]
    }
  ]
}