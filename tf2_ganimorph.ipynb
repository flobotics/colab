{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2-ganimorph.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flobotics/colab/blob/master/tf2_ganimorph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3N_53xvtUQb",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/alpha/tutorials/generative/pix2pix\n",
        "\n",
        "https://www.tensorflow.org/alpha/tutorials/generative/dcgan\n",
        "\n",
        "https://www.tensorflow.org/alpha/tutorials/load_data/images#load_and_format_the_images\n",
        "\n",
        "https://www.tensorflow.org/guide/performance/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B53NJP7dt9xT",
        "colab_type": "text"
      },
      "source": [
        "@inproceedings{Gokaslan2018,\n",
        "  title={Improving Shape Deformation in Unsupervised Image to Image Translation},\n",
        "  author={Aaron Gokaslan and Vivek Ramanujan and Daniel Ritchie and Kwang In Kim and James Tompkin},\n",
        "  booktitle={European Conference on Computer Vision},\n",
        "  year={2018}\n",
        "}\n",
        "\n",
        "https://github.com/brownvc/ganimorph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAJoNuk5QHU2",
        "colab_type": "code",
        "outputId": "a94139fb-1577-41ac-a0bf-b7de8c33a812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXrMqG2hntC5",
        "colab_type": "code",
        "outputId": "2e46728c-7238-43a2-b899-01fddc3da722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip3 install tensorflow-addons"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4FTapNoc7N5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "#from tensorpack import *\n",
        "#from tensorpack.utils.viz import *\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "#from tensorpack import (FeedfreeTrainerBase, QueueInput,\n",
        "#                        ModelDesc, DataFlow, StagingInputWrapper,\n",
        "#                        MultiGPUTrainerBase, LeastLoadedDeviceSetter)\n",
        "#from tensorpack.tfutils.summary import add_moving_summary\n",
        "\n",
        "from tensorflow.python.training import moving_averages\n",
        "\n",
        "\n",
        "#import tensorpack.tfutils.symbolic_functions as symbf\n",
        "\n",
        "import cv2\n",
        "import os, sys\n",
        "import argparse\n",
        "from six.moves import map, zip\n",
        "from glob import glob\n",
        "\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#from tensorpack import *\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import IPython.display as display\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42GSJFUiZmZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.executing_eagerly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLpmUIEpKQSl",
        "colab_type": "text"
      },
      "source": [
        "# Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkcpyr6heK4C",
        "colab_type": "code",
        "outputId": "fa46ac24-061e-4ee5-f603-ea17a02838f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeSB753GeZZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir /content/log\n",
        "#!cp -a /content/gdrive/My\\ Drive/images/model-11/* /content/log/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMhjxVqpgH3M",
        "colab_type": "text"
      },
      "source": [
        "# Copy train and test data from e.g. Google-Drive to colab-notebook-machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaIQ_Lw5ebCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/data/\n",
        "\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/trainA.tar.gz /content/data/\n",
        "!tar -xzf /content/data/trainA.tar.gz -C /content/data/\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/trainB.tar.gz /content/data/\n",
        "!tar -xzf /content/data/trainB.tar.gz -C /content/data/\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/testA.tar.gz /content/data/\n",
        "!tar -xzf /content/data/testA.tar.gz -C /content/data/\n",
        "\n",
        "!cp -a /content/gdrive/My\\ Drive/images/new-images/testB.tar.gz /content/data/\n",
        "!tar -xzf /content/data/testB.tar.gz -C /content/data/\n",
        "\n",
        "!rm /content/data/testA.tar.gz\n",
        "!rm /content/data/testB.tar.gz\n",
        "!rm /content/data/trainA.tar.gz\n",
        "!rm /content/data/trainB.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMABggQHRw0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SHAPE = 128\n",
        "#BATCH = 16\n",
        "TEST_BATCH = 32\n",
        "NF = 64  # channel size\n",
        "\n",
        "BATCH_SIZE  = 1\n",
        "#FLAGS.batch_size = BATCH\n",
        "#FLAGS.prefetch_buffer_size = BATCH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnqVhD777SF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_preprocess_image(path):\n",
        "  print_debug = 1\n",
        "  \n",
        "  image = tf.io.read_file(path)\n",
        "  \n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  if print_debug: print(\"original image-shape:{}\".format(image.shape))\n",
        "  if print_debug: print(\"original image-dtype:{}\".format(image.dtype))\n",
        "  \n",
        "  image = tf.image.resize(image, [SHAPE, SHAPE])\n",
        "  image /= 255.0  # normalize to [0,1] range\n",
        "  image = tf.transpose(image, perm=[2, 0, 1]) #seemed to break something, transpose ZipDataset\n",
        "\n",
        "  if print_debug: print(\"preprocessed image-shape:{}\".format(image.shape))\n",
        "  #if print_debug: print(\"preprocessed image-numpy-min:{}\".format(image.numpy().min()))\n",
        "  #if print_debug: print(\"preprocessed image-numpy-max:{}\".format(image.numpy().max()))\n",
        "  \n",
        "  return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPreL8O1EP3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_image_paths(dir):\n",
        "  print_debug = 0\n",
        "  \n",
        "  data_root = pathlib.Path(dir)\n",
        "  if print_debug: print(\"image-dir:{}\".format(data_root))\n",
        "  \n",
        "  all_image_paths = list(data_root.glob('*'))\n",
        "  all_image_paths = [str(path) for path in all_image_paths]\n",
        "  random.shuffle(all_image_paths)\n",
        "\n",
        "  if print_debug: print(\"image-count:{}\".format(len(all_image_paths)))\n",
        "  \n",
        "  if print_debug:\n",
        "    print(\"3 Pictures from this set\")\n",
        "    for n in range(3):\n",
        "      image_path = random.choice(all_image_paths)\n",
        "      display.display(display.Image(image_path))\n",
        "    \n",
        "  return all_image_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQDEdSKrLXNF",
        "colab_type": "text"
      },
      "source": [
        "# Build Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7NAZUxrRZr4",
        "colab_type": "code",
        "outputId": "7541752a-393b-4d63-b920-4a7fb015574f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print_debug = 1\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "trainA_dir = \"/content/data/trainA\"\n",
        "trainB_dir = \"/content/data/trainB\"\n",
        "testA_dir = \"/content/data/testA\"\n",
        "testB_dir = \"/content/data/testB\"\n",
        "\n",
        "#---Create Dataset with trainA\n",
        "all_image_paths = get_all_image_paths(trainA_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_trainA = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_trainA))\n",
        "\n",
        "#---Create Dataset with trainB\n",
        "all_image_paths = get_all_image_paths(trainB_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_trainB = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_trainA))\n",
        "\n",
        "  #--- Create ZipDataset\n",
        "image_ds_trainA_B = tf.data.Dataset.zip((image_ds_trainA, image_ds_trainB))\n",
        "if print_debug: print(\"zipDataset  shapes/types:{}\".format(image_ds_trainA_B))\n",
        "\n",
        "#---Create Dataset with testA\n",
        "all_image_paths = get_all_image_paths(testA_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_testA = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_testA))\n",
        "\n",
        "#---Create Dataset with testB\n",
        "all_image_paths = get_all_image_paths(testB_dir)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "image_ds_testB = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "if print_debug: print(\"Dataset shape/type:{}\".format(image_ds_testB))\n",
        "\n",
        "#--- Create ZipDataset\n",
        "image_ds_testA_B = tf.data.Dataset.zip((image_ds_testA, image_ds_testB))\n",
        "if print_debug: print(\"zipDataset  shapes/types:{}\".format(image_ds_testA_B))\n",
        "#print(\"len:{}\".format(image_ds_testA_B.))\n",
        "\n",
        "#------\n",
        "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
        "# completely shuffled.\n",
        "image_ds_trainA_B = image_ds_trainA_B.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "image_ds_trainA_B = image_ds_trainA_B.repeat()\n",
        "image_ds_trainA_B = image_ds_trainA_B.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=SHUFFLE_BUFFER_SIZE))\n",
        "image_ds_trainA_B = image_ds_trainA_B.batch(BATCH_SIZE)\n",
        "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
        "image_ds_trainA_B = image_ds_trainA_B.prefetch(buffer_size=AUTOTUNE)\n",
        "if print_debug: print(\"image_ds_trainA_B shape/type {}\".format(image_ds_trainA_B))\n",
        "\n",
        "#test-images ds\n",
        "image_ds_testA_B = image_ds_testA_B.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "image_ds_testA_B = image_ds_testA_B.repeat()\n",
        "image_ds_testA_B = image_ds_testA_B.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=SHUFFLE_BUFFER_SIZE))\n",
        "image_ds_testA_B = image_ds_testA_B.batch(BATCH_SIZE)\n",
        "image_ds_testA_B = image_ds_testA_B.prefetch(buffer_size=AUTOTUNE)\n",
        "if print_debug: print(\"image_ds_testA_B shape/type {}\".format(image_ds_testA_B))\n",
        "\n",
        "  \n",
        "#for input_image, target in image_ds_testA_B:\n",
        "#  print(\"out:{} {}\".format(input_image, target))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "zipDataset  shapes/types:<ZipDataset shapes: ((3, 128, 128), (3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "original image-shape:(None, None, 3)\n",
            "original image-dtype:<dtype: 'uint8'>\n",
            "preprocessed image-shape:(3, 128, 128)\n",
            "Dataset shape/type:<ParallelMapDataset shapes: (3, 128, 128), types: tf.float32>\n",
            "zipDataset  shapes/types:<ZipDataset shapes: ((3, 128, 128), (3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "image_ds_trainA_B shape/type <PrefetchDataset shapes: ((None, 3, 128, 128), (None, 3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "image_ds_testA_B shape/type <PrefetchDataset shapes: ((None, 3, 128, 128), (None, 3, 128, 128)), types: (tf.float32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qNnanKKTMCo",
        "colab_type": "text"
      },
      "source": [
        "# build the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLpSzPzunVqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def INReLU(self,x, name=None):\n",
        "  x = tfa.layers.InstanceNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTurwOdnnZhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def INLReLU(x, name=None):\n",
        "  x = tfa.layers.InstanceNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hONyQzQ6ndz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BNLReLU(x, name):\n",
        "    x = BatchNorm('bn', x)\n",
        "    return tf.nn.relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHpB6pfI-Je1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = \"channels_first\"\n",
        "debug_show_shapes = 0\n",
        "res_input = tf.Variable([3, 128, 128])\n",
        "res_l = tf.Variable([3, 128, 128])\n",
        "\n",
        "def build_res_block(x, name, chan, first=False):\n",
        "  #input = x\n",
        "  print(\"x-shape:{}\".format(x))\n",
        "  res_input = x\n",
        "  l = layers.Conv2D(filters=NF*2,\n",
        "                    kernel_size=3,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    data_format=df,\n",
        "                    kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                    use_bias=False)(x)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "  l = layers.Conv2D(filters=NF*2,\n",
        "                    kernel_size=3,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    data_format=df,\n",
        "                    kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                    use_bias=False)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "  #l = tf.concat([l, input], axis=1)\n",
        "  l = tf.concat([l, res_input], axis=1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "  l = layers.Conv2D(filters=NF*2,\n",
        "                    kernel_size=3,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    data_format=df,\n",
        "                    kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                    use_bias=False)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"layer1: {}\".format(l.shape))\n",
        "  \n",
        "  return l\n",
        "\n",
        "def res_group(input, name, depth, channels):\n",
        "  res_l = input\n",
        "  for k in range(depth):\n",
        "    res_l = build_res_block(res_l, name + ('/res%d' % k), channels,\n",
        "                           first=(k==0))\n",
        "    \n",
        "  return res_l\n",
        "  \n",
        "#def res_group(input, name, depth, channels):\n",
        "#  l = input\n",
        "#  for k in range(depth):\n",
        "#    l = build_res_block(l, name + ('/res%d' % k), channels,\n",
        "#            first=(k==0))\n",
        "#  return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv6fy9A-qOz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug_show_shapes = 1\n",
        "subDepth = 3\n",
        "df = \"channels_first\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPs8FP-Hle1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  inputs = tf.keras.Input(shape=(3, 128, 128))  # Returns a placeholder tensor\n",
        "  \n",
        "\n",
        "  \n",
        "  if debug_show_shapes: print(\"inputs: {}\".format(inputs.shape))\n",
        "  \n",
        "  conv0 = layers.Conv2D(filters=NF, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=tf.nn.relu, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(inputs)\n",
        "  \n",
        "  if debug_show_shapes: print(\"conv0: {}\".format(conv0.shape))\n",
        "  \n",
        "  conv1 = layers.Conv2D(filters=NF*2,\n",
        "                        kernel_size=4,\n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        data_format=df,\n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                        use_bias=False,\n",
        "                        activation=INLReLU)(conv0)\n",
        "\n",
        "  if debug_show_shapes: print(\"conv1: {}\".format(conv1.shape))\n",
        "  \n",
        "  #-------------------------\n",
        "  layer1 = res_group(conv1, 'layer1', subDepth, NF*2)\n",
        "  \n",
        "  #-----------------\n",
        "  conv2 = layers.Conv2D(filters=NF*4,\n",
        "                        kernel_size=4,\n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        data_format=df,\n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                        use_bias=False,\n",
        "                        activation=INLReLU)(layer1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"conv2: {}\".format(conv2.shape))\n",
        "  #----------------\n",
        "  \n",
        "  layer2 = res_group(conv2, 'layer2', subDepth, NF*4)\n",
        "  \n",
        "  #-----------------\n",
        "  conv3 = layers.Conv2D(filters=NF*8,\n",
        "                        kernel_size=4,\n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        data_format=df,\n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                        use_bias=False,\n",
        "                        activation=INLReLU)(layer2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"conv3: {}\".format(conv3.shape))\n",
        "  #---------------\n",
        "  l = res_group(conv3, 'layer3', subDepth, NF*8)\n",
        "  \n",
        "  #--------------\n",
        "  \n",
        "  deconv0 = layers.Conv2DTranspose(filters=NF*4,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False,\n",
        "                                   activation=INLReLU)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv0: {}\".format(deconv0.shape))\n",
        "  #-----------------\n",
        "  up1 = tf.concat([deconv0, layer2], axis=1)\n",
        "  \n",
        "  #------------\n",
        "  b_layer_2 = res_group(up1, 'blayer2', subDepth, NF * 4)\n",
        "  \n",
        "  #----------\n",
        "  deconv1 = layers.Conv2DTranspose(filters=NF*2,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False,\n",
        "                                   activation=INLReLU)(b_layer_2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv1: {}\".format(deconv1.shape))\n",
        "  \n",
        "  #-----------\n",
        "  up2 = tf.concat([deconv1, layer1], axis=1)\n",
        "  \n",
        "  #------------\n",
        "  b_layer_1 = res_group(up2, 'blayer1', subDepth, NF * 2)\n",
        "  \n",
        "  #----------\n",
        "  deconv2 = layers.Conv2DTranspose(filters=NF*1,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False,\n",
        "                                   activation=INLReLU)(b_layer_1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv2: {}\".format(deconv2.shape))\n",
        "  #-----------\n",
        "  deconv3 = layers.Conv2DTranspose(filters=3,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=2,\n",
        "                                   padding='same',\n",
        "                                   data_format=df,\n",
        "                                   kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"),\n",
        "                                   use_bias=False, \n",
        "                                   activation=tf.sigmoid)(deconv2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"deconv3: {}\".format(deconv3.shape))\n",
        "  #-----------\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=deconv3)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvSfrg0mUISo",
        "colab_type": "code",
        "outputId": "7574c0ff-5491-405c-85f2-46b6c63d4a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2445
        }
      },
      "source": [
        "generator = Generator()\n",
        "\n",
        "\n",
        "noise = tf.random.normal([1, 3, 128, 128])\n",
        "\n",
        "i = image_ds_testA.take(1)\n",
        "print(\"i:{}\".format(list(i)))\n",
        "\n",
        "\n",
        "\n",
        "gen_output = generator(noise, training=False)\n",
        "\n",
        "gen_output = tf.transpose(gen_output, [0, 2, 3, 1])\n",
        "print(gen_output.shape)\n",
        "\n",
        "plt.imshow(gen_output[0,...])"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: (None, 3, 128, 128)\n",
            "conv0: (None, 64, 64, 64)\n",
            "conv1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_342/re_lu_67/Relu:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_345/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_348/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "conv2: (None, 256, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_352/re_lu_68/Relu:0\", shape=(None, 256, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 384, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_355/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_358/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "conv3: (None, 512, 8, 8)\n",
            "x-shape:Tensor(\"conv2d_362/re_lu_69/Relu:0\", shape=(None, 512, 8, 8), dtype=float32)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 640, 8, 8)\n",
            "layer1: (None, 128, 8, 8)\n",
            "x-shape:Tensor(\"conv2d_365/Conv2D:0\", shape=(None, 128, 8, 8), dtype=float32)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 256, 8, 8)\n",
            "layer1: (None, 128, 8, 8)\n",
            "x-shape:Tensor(\"conv2d_368/Conv2D:0\", shape=(None, 128, 8, 8), dtype=float32)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 128, 8, 8)\n",
            "l: (None, 256, 8, 8)\n",
            "layer1: (None, 128, 8, 8)\n",
            "deconv0: (None, 256, 16, 16)\n",
            "x-shape:Tensor(\"concat_117:0\", shape=(None, 384, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 512, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_374/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "x-shape:Tensor(\"conv2d_377/Conv2D:0\", shape=(None, 128, 16, 16), dtype=float32)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 128, 16, 16)\n",
            "l: (None, 256, 16, 16)\n",
            "layer1: (None, 128, 16, 16)\n",
            "deconv1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"concat_121:0\", shape=(None, 256, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 384, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_383/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "x-shape:Tensor(\"conv2d_386/Conv2D:0\", shape=(None, 128, 32, 32), dtype=float32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 128, 32, 32)\n",
            "l: (None, 256, 32, 32)\n",
            "layer1: (None, 128, 32, 32)\n",
            "deconv2: (None, 64, 64, 64)\n",
            "deconv3: (None, 3, 128, 128)\n",
            "i:[<tf.Tensor: id=25110, shape=(3, 128, 128), dtype=float32, numpy=\n",
            "array([[[0.04191177, 0.06470589, 0.03921569, ..., 0.09387255,\n",
            "         0.09656863, 0.1002451 ],\n",
            "        [0.03382353, 0.05      , 0.03921569, ..., 0.08504902,\n",
            "         0.07745098, 0.07230392],\n",
            "        [0.03455883, 0.03455883, 0.04093137, ..., 0.07720588,\n",
            "         0.08627451, 0.08995098],\n",
            "        ...,\n",
            "        [0.04019608, 0.04387255, 0.02965686, ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.04240196, 0.04387255, 0.02965686, ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.03210784, 0.04240196, 0.04362745, ..., 0.        ,\n",
            "         0.        , 0.        ]],\n",
            "\n",
            "       [[0.00735294, 0.02941176, 0.00392157, ..., 0.06642157,\n",
            "         0.06911765, 0.07279412],\n",
            "        [0.00367647, 0.01470588, 0.00392157, ..., 0.06348039,\n",
            "         0.05588235, 0.05073529],\n",
            "        [0.        , 0.        , 0.00367647, ..., 0.05735294,\n",
            "         0.06789216, 0.07156863],\n",
            "        ...,\n",
            "        [0.00073529, 0.00661765, 0.00098039, ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.00073529, 0.00661765, 0.00098039, ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.        , 0.00588235, 0.01127451, ..., 0.        ,\n",
            "         0.        , 0.        ]],\n",
            "\n",
            "       [[0.00245098, 0.00980392, 0.        , ..., 0.        ,\n",
            "         0.00367647, 0.00808824],\n",
            "        [0.0002451 , 0.00098039, 0.        , ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.00220588,\n",
            "         0.00514706, 0.00735294],\n",
            "        ...,\n",
            "        [0.0127451 , 0.01936275, 0.00808824, ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.01495098, 0.01936275, 0.00808824, ..., 0.        ,\n",
            "         0.        , 0.        ],\n",
            "        [0.00465686, 0.01789216, 0.02205882, ..., 0.        ,\n",
            "         0.        , 0.        ]]], dtype=float32)>]\n",
            "(1, 128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f72529366d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC1E7K4+pWw2uAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwuDmsZMy9CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGQRQzOfttj7",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFvOoSsVaj03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "  debug_show_shapes = 0\n",
        "  \n",
        "  subDepth = 3\n",
        "  df = \"channels_first\"\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(3, 128, 128))  # Returns a placeholder tensor\n",
        "  if debug_show_shapes: print(\"inputs: {}\".format(inputs.shape))\n",
        "  \n",
        "  l = layers.Conv2D(filters=NF*2, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=tf.nn.relu, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(inputs)\n",
        "  \n",
        "  if debug_show_shapes: print(\"l: {}\".format(l.shape))\n",
        "   \n",
        "  #----\n",
        "  \n",
        "  relu1 = layers.Conv2D(filters=NF*4, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(l)\n",
        "  \n",
        "  if debug_show_shapes: print(\"relu1: {}\".format(relu1.shape))\n",
        "    \n",
        "  #-----------------\n",
        "    \n",
        "  relu2 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=4, \n",
        "                        strides=2,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(relu1)\n",
        "  \n",
        "  if debug_show_shapes: print(\"relu2: {}\".format(relu2.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  relu3 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(relu2)\n",
        "  \n",
        "  if debug_show_shapes: print(\"relu3: {}\".format(relu3.shape))\n",
        "    \n",
        "  #-----------------\n",
        "\n",
        "  \n",
        "  atrous = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False,\n",
        "                        dilation_rate=2,\n",
        "                        bias_initializer=None)(relu3)\n",
        "  ##INLReLU\n",
        "  if debug_show_shapes: print(\"atrous: {}\".format(atrous.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  atrous2 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False,\n",
        "                        dilation_rate=4,\n",
        "                        bias_initializer=None)(atrous)\n",
        "  ##INLReLU\n",
        "  if debug_show_shapes: print(\"atrous2: {}\".format(atrous2.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  atrous3 = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False,\n",
        "                        dilation_rate=8,\n",
        "                        bias_initializer=None)(atrous2)\n",
        "  ##INLReLU\n",
        "  if debug_show_shapes: print(\"atrous3: {}\".format(atrous3.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  merge = tf.concat([relu3, atrous3], axis=1)\n",
        "  if debug_show_shapes: print(\"merge: {}\".format(merge.shape))\n",
        "  #-----------------\n",
        "  \n",
        "  clean = layers.Conv2D(filters=NF*8, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=INLReLU, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(merge)\n",
        "  \n",
        "  if debug_show_shapes: print(\"clean: {}\".format(clean.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  lsgan = layers.Conv2D(filters=1, \n",
        "                        kernel_size=3, \n",
        "                        strides=1,\n",
        "                        padding='same',\n",
        "                        activation=tf.identity, \n",
        "                        data_format=df, \n",
        "                        kernel_initializer=tf.initializers.VarianceScaling(scale=0.333, distribution=\"uniform\"), \n",
        "                        use_bias=False)(clean)\n",
        "  \n",
        "  if debug_show_shapes: print(\"lsgan: {}\".format(lsgan.shape))\n",
        "    \n",
        "  #-----------------\n",
        "  \n",
        "  model = tf.keras.Model(inputs=inputs, outputs=[lsgan, [relu1, relu2, relu3, atrous, atrous2, atrous3, clean]] )\n",
        "  \n",
        "  if debug_show_shapes: model.summary()\n",
        "\n",
        "  return model  #whats with the other outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qATmfX6bVDMh",
        "colab_type": "code",
        "outputId": "060b3881-39dd-4733-ac5a-cf5137964d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "discriminator = Discriminator()\n",
        "\n",
        "noise = tf.random.normal([1, 3, 128, 128])\n",
        "\n",
        "disc_out,a = discriminator([noise, gen_output], training=False)\n",
        "\n",
        "print(disc_out.shape)\n",
        "disc_out = tf.transpose(disc_out, [0, 2, 3, 1])\n",
        "print(disc_out.shape)\n",
        "\n",
        "#plt.imshow(disc_out[0,...])\n",
        "\n",
        "\n",
        "plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "plt.colorbar()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 16, 16)\n",
            "(1, 16, 16, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f724f50f780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAD8CAYAAAAbkUOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLxMw-xvK4Je",
        "colab_type": "text"
      },
      "source": [
        "# losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_NCxP-CGYVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_match_loss(feats_real, feats_fake):\n",
        "  print(\"gfml-1\")\n",
        "  #print(feats_fake)\n",
        "  losses = []\n",
        "  for real, fake in zip(feats_real, feats_fake):\n",
        "      loss = tf.reduce_mean(tf.math.squared_difference(\n",
        "          tf.reduce_mean(real, 0),\n",
        "          tf.reduce_mean(fake, 0)),\n",
        "          name='mse_feat_' + real.op.name)\n",
        "      losses.append(loss)\n",
        "  ret = tf.reduce_mean(losses, name='feature_match_loss')\n",
        "  #add_moving_summary(ret)\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyHxPp0vGiCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_normalize(loss, update_condition, epsilon=1e-10):\n",
        "  print(\"loss-norm1:{}\".format(loss))\n",
        "  print(\"loss-norm2:{}\".format(update_condition))\n",
        "  \n",
        "  # Variable used for storing the scalar-value of the loss-function.\n",
        "  loss_value = tf.Variable(1.0, name='loss_scalar_val_' + loss.op.name,\n",
        "          trainable=False)\n",
        "\n",
        "  loss_value_smooth = (tf.Variable(1.0, name='loss_smooth_' +\n",
        "          loss.op.name, trainable=False))\n",
        "\n",
        "  #TODO don't update if is_training\n",
        "  ma_loss_value = (\n",
        "      moving_averages.assign_moving_average(\n",
        "              loss_value_smooth, loss, 0.9999, zero_debias=False, name='loss_EMA'\n",
        "          )\n",
        "      )\n",
        "\n",
        "  #tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, ma_loss_value)\n",
        "  # Expression used for either updating the scalar-value or\n",
        "  # just re-using the old value.\n",
        "  # Note that when loss_value.assign(loss) is evaluated, it\n",
        "  # first evaluates the loss-function which is a TensorFlow\n",
        "  # expression, and then assigns the resulting scalar-value to\n",
        "  # the loss_value variable.\n",
        "  print(\"upd-cond:{}\".format(update_condition))\n",
        "  print(\"ma-loss:{}\".format(ma_loss_value))\n",
        "  print(\"loss-val:{}\".format(loss_value))\n",
        "  loss_value_updated = tf.cond(update_condition,\n",
        "                               lambda: loss_value.assign(ma_loss_value),\n",
        "                               lambda: loss_value)\n",
        "\n",
        "\n",
        "  print(\"loss-upd\")\n",
        "  # Expression for the normalized loss-function.\n",
        "  loss_normalized = loss / (loss_value_updated + epsilon)\n",
        "  print(\"loss-upd-1\")\n",
        "  #add_moving_summary(tf.identity(loss_value, name='loss_scalar_' + loss.op.name))\n",
        "\n",
        "  return loss_normalized\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEUBZUZrRLg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _tf_fspecial_gauss(size, sigma):\n",
        "  \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "  \"\"\"\n",
        "  x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "\n",
        "  x_data = np.expand_dims(x_data, axis=-1)\n",
        "  x_data = np.expand_dims(x_data, axis=-1)\n",
        "\n",
        "  y_data = np.expand_dims(y_data, axis=-1)\n",
        "  y_data = np.expand_dims(y_data, axis=-1)\n",
        "\n",
        "  x = tf.constant(x_data, dtype=tf.float32)\n",
        "  y = tf.constant(y_data, dtype=tf.float32)\n",
        "\n",
        "  g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
        "  return g / tf.reduce_sum(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KXiarnhREpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_ssim(img1, img2, cs_map=False, mean_metric=True, size=8, sigma=1.5):\n",
        "  window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
        "  K1 = 0.03\n",
        "  K2 = 0.05\n",
        "  L = 1  # depth of image (255 in case the image has a differnt scale)\n",
        "  C1 = (K1*L)**2\n",
        "  C2 = (K2*L)**2\n",
        "  mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
        "  mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1], padding='VALID')\n",
        "  mu1_sq = mu1*mu1\n",
        "  mu2_sq = mu2*mu2\n",
        "  mu1_mu2 = mu1*mu2\n",
        "  sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
        "  sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
        "  sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
        "  sigma1_sq = tf.abs(sigma1_sq)\n",
        "  sigma2_sq = tf.abs(sigma2_sq)\n",
        "  sigma12 = tf.abs(sigma12)\n",
        "  if cs_map:\n",
        "\n",
        "      value = (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                  (sigma1_sq + sigma2_sq + C2)),\n",
        "              (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
        "  else:\n",
        "      value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                  (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "  if mean_metric:\n",
        "      value = tf.reduce_mean(value)\n",
        "  return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M2b0P0kQ9i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_ms_ssim(img1, img2, mean_metric=True, level=5):\n",
        "  #From NCHW to NHWC\n",
        "  img1 = tf.transpose(img1, [0, 2, 3, 1])\n",
        "  img2 = tf.transpose(img2, [0, 2, 3, 1])\n",
        "\n",
        "  weight = tf.constant([0.0448, 0.2856, 0.3001, 0.2363, 0.1333], dtype=tf.float32)\n",
        "  mssim = []\n",
        "  mcs = []\n",
        "  for l in range(level):\n",
        "      ssim_map, cs_map = tf_ssim(img1, img2, cs_map=True, mean_metric=False)\n",
        "      mssim.append(tf.reduce_mean(ssim_map))\n",
        "      mcs.append(tf.reduce_mean(cs_map))\n",
        "      filtered_im1 = tf.nn.avg_pool(img1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "      filtered_im2 = tf.nn.avg_pool(img2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "      img1 = filtered_im1\n",
        "      img2 = filtered_im2\n",
        "\n",
        "  # list to tensor of dim D+1\n",
        "  mssim = tf.stack(mssim, axis=0)\n",
        "  mcs = tf.stack(mcs, axis=0)\n",
        "\n",
        "  value = (tf.reduce_prod(mcs[0:level-1]**weight[0:level-1])*\n",
        "                          (mssim[level-1]**weight[level-1]))\n",
        "\n",
        "  if mean_metric:\n",
        "      value = tf.reduce_mean(value)\n",
        "  return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF5iWLVAQrh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_dssim(img1, img2):\n",
        "  img1 = tf.unstack(tf.expand_dims(img1, axis=2), axis=1)\n",
        "  img2 = tf.unstack(tf.expand_dims(img2, axis=2), axis=1)\n",
        "  value = tf.stack([tf_ms_ssim(i1, i2) for i1, i2 in zip(img1, img2)], axis=0)\n",
        "  return tf.subtract(1.0, tf.reduce_sum(value)/3, name='DSSIM_loss')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErsvNLhPTGqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_losses(logits_real, logits_fake):\n",
        "  #Build standard GAN loss and set `self.g_loss` and `self.d_loss`.\n",
        "  #D and G play two-player minimax game with value function V(G,D)\n",
        "  #  min_G max _D V(D, G) = IE_{x ~ p_data} [log D(x)] + IE_{z ~ p_fake} [log (1 - D(G(z)))]\n",
        "  #Args:\n",
        "  #    logits_real (tf.Tensor): discrim logits from real samples\n",
        "  #    logits_fake (tf.Tensor): discrim logits from fake samples produced by generator\n",
        "\n",
        "  with tf.name_scope(\"GAN_loss\"):\n",
        "    score_real = tf.sigmoid(logits_real)\n",
        "    score_fake = tf.sigmoid(logits_fake)\n",
        "    #tf.summary.histogram('score-real', score_real)\n",
        "    #tf.summary.histogram('score-fake', score_fake)\n",
        "\n",
        "    with tf.name_scope(\"discrim\"):\n",
        "        d_loss_pos = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=logits_real, labels=tf.ones_like(logits_real)), name='loss_real')\n",
        "        d_loss_neg = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=logits_fake, labels=tf.zeros_like(logits_fake)), name='loss_fake')\n",
        "\n",
        "        d_pos_acc = tf.reduce_mean(tf.cast(score_real > 0.5, tf.float32), name='accuracy_real')\n",
        "        d_neg_acc = tf.reduce_mean(tf.cast(score_fake < 0.5, tf.float32), name='accuracy_fake')\n",
        "\n",
        "        d_accuracy = tf.add(.5 * d_pos_acc, .5 * d_neg_acc, name='accuracy')\n",
        "        d_loss = tf.add(.5 * d_loss_pos, .5 * d_loss_neg, name='loss')\n",
        "\n",
        "    with tf.name_scope(\"gen\"):\n",
        "        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=logits_fake, labels=tf.ones_like(logits_fake)), name='loss')\n",
        "        g_accuracy = tf.reduce_mean(tf.cast(score_fake > 0.5, tf.float32), name='accuracy')\n",
        "\n",
        "    #add_moving_summary(g_loss, d_loss, d_accuracy, g_accuracy)\n",
        "    \n",
        "    return g_loss, d_loss, d_accuracy, g_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpT89fEdmnHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  d_loss = tf.add(D_loss_A, D_loss_B, name='D_loss_total')\n",
        "  \n",
        "  return d_loss\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KepfzD6nm2xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(A, ABA, B, BAB):\n",
        "  \n",
        "  recon_loss_A = tf_dssim(A, ABA)\n",
        "  if print_debug: print(\"recon_loss_A-shape: {}\".format(recon_loss_A.shape))\n",
        "  if print_debug: print(\"A-shape: {}\".format(A.shape))\n",
        "  if print_debug: print(\"ABA-shape: {}\".format(ABA.shape))\n",
        "  recon_loss_A_l = tf.compat.v1.losses.absolute_difference(A,\n",
        "                                            ABA,\n",
        "                                            reduction=tf.compat.v1.losses.Reduction.MEAN)\n",
        "  if print_debug: print(\"recon_loss_A_l-shape: {}\".format(recon_loss_A_l.shape))\n",
        "\n",
        "  # gan loss\n",
        "  g_loss, d_loss, d_accuracy, g_accuracy = build_losses(A_dis_real, A_dis_fake)\n",
        "  G_loss_A = g_loss\n",
        "  D_loss_A = d_loss\n",
        "  # feature matching loss\n",
        "  if print_debug: print(A_feats_fake)\n",
        "  fm_loss_A = get_feature_match_loss(A_feats_real, A_feats_fake)\n",
        "  #-------------------\n",
        "\n",
        "  recon_loss_B = tf_dssim(B, BAB)\n",
        "  if print_debug: print(\"recon_loss_B-shape: {}\".format(recon_loss_B.shape))\n",
        "\n",
        "  recon_loss_B_l = tf.compat.v1.losses.absolute_difference(B,\n",
        "                                            BAB,\n",
        "                                            reduction=tf.compat.v1.losses.Reduction.MEAN)\n",
        "  if print_debug: print(\"recon_loss_B_l-shape: {}\".format(recon_loss_B_l.shape))\n",
        "\n",
        "  g_loss, d_loss, d_accuracy, g_accuracy = build_losses(B_dis_real, B_dis_fake)\n",
        "  G_loss_B = g_loss\n",
        "  D_loss_B = d_loss# + grad_penalty_B\n",
        "  fm_loss_B = get_feature_match_loss(B_feats_real, B_feats_fake)\n",
        "  #-------------------\n",
        "\n",
        "  global_step = np.int64(1)   #get_global_step_var()\n",
        "  rate = 0.01  #tf.train.piecewise_constant(global_step, [np.int64(15000), np.int64(25000), np.int64(50000), np.int64(100000)], [0.01, 0.10, 0.15, 0.20, 0.25])\n",
        "  #rate = tf.identity(rate, name='rate')   # mitigate a TF bug\n",
        "  loss_update = tf.logical_or(tf.equal(global_step, tf.constant(36,\n",
        "      dtype=np.int64)), tf.equal(global_step % 90, tf.constant(0, dtype=np.int64)))\n",
        "  rate = tf.constant(0.33, np.float32, name='static_rate')\n",
        "\n",
        "\n",
        "  g_loss = tf.add_n([\n",
        "      (loss_normalize(G_loss_A + G_loss_B, loss_update) * 0.7 +\n",
        "      loss_normalize(fm_loss_A + fm_loss_B, loss_update) * 0.3) * (1 - rate),\n",
        "      (loss_normalize((recon_loss_A + recon_loss_B), loss_update) *\n",
        "          0.7 +\n",
        "  loss_normalize((recon_loss_A_l + recon_loss_B_l),\n",
        "              loss_update) * 0.3) * rate], name='G_loss_total')\n",
        "\n",
        "\n",
        "  d_loss = tf.add(D_loss_A, D_loss_B, name='D_loss_total')\n",
        "\n",
        "  #@TODO what todo? collect_variables('gen', 'discrim')\n",
        "\n",
        "  g_loss = g_loss\n",
        "  d_loss = d_loss \n",
        "\n",
        "  \n",
        "  return g_loss, d_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-9Z01QLVjF",
        "colab_type": "text"
      },
      "source": [
        "# optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk036iXixrHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lr = tf.get_variable('learning_rate', initializer=2e-4,\n",
        "#                 trainable=False)\n",
        "#        return tf.train.AdamOptimizer(lr, beta1=0.5)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwHsakYaLhz9",
        "colab_type": "text"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKNKgCD5Vzey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_variables(self, g_scope='gen', d_scope='discrim'):\n",
        "  #\"\"\"\n",
        "  #Assign `self.g_vars` to the parameters under scope `g_scope`,\n",
        "  #and same with `self.d_vars`.\n",
        "  #\"\"\"\n",
        "  self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, g_scope)\n",
        "  assert self.g_vars\n",
        "  self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, d_scope)\n",
        "  assert self.d_vars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQatM82Ty-EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A = tf.Variable(1.0)\n",
        "AB = tf.Variable([3, 128, 128])\n",
        "#AB = None\n",
        "BA = None\n",
        "ABA = None\n",
        "BAB = None\n",
        "\n",
        "print_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdQWnkOGx4gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(A, B):\n",
        "#  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "#    gen_output = generator(input_image, training=True)\n",
        "#\n",
        "#    disc_real_output = discriminator([input_image, target], training=True)\n",
        "#    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "#\n",
        "#    gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "#    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "#  generator_gradients = gen_tape.gradient(gen_loss,\n",
        "#                                          generator.trainable_variables)\n",
        "#  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "#                                               discriminator.trainable_variables)\n",
        "\n",
        "#  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "#                                          generator.trainable_variables))\n",
        "#  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "#                                              discriminator.trainable_variables))\n",
        "  \n",
        "  \n",
        "  if print_debug: print(\"train step\")\n",
        "  \n",
        "  print(\"train\")\n",
        "\n",
        "  \n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    AB = generator(A, training=True)\n",
        "    #AB=A\n",
        "    if print_debug: print(\"AB:\")\n",
        "    #BA = generator(B, training=True)\n",
        "    #ABA = generator(AB, training=True)\n",
        "    #BAB = generator(BA, training=True)\n",
        "    if print_debug: print(\"BAB\")\n",
        "    \n",
        "    #A_dis_real, A_feats_real = discriminator(A, training=True)\n",
        "    #A_dis_fake, A_feats_fake = discriminator(BA, training=True)\n",
        "    #B_dis_real, B_feats_real = discriminator(B, training=True)\n",
        "    #B_dis_fake, B_feats_fake = discriminator(AB, training=True)\n",
        "  \n",
        "    #------------\n",
        "    #g_loss, d_loss = generator_loss(A, ABA, B, BAB)\n",
        "      \n",
        "      \n",
        "    \n",
        "    if print_debug: print(\"end train step\")\n",
        "    \n",
        "    #add_moving_summary(recon_loss_A, recon_loss_B, rate, g_loss, d_loss,\n",
        "    #        recon_loss_A_l, recon_loss_B_l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbP4P_KFxtph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM0iKglUyVOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for input_image, target in dataset:\n",
        "      print(\"loop\")\n",
        "      train_step(input_image, target)\n",
        "      print(\"loop1\")\n",
        "\n",
        "    print(\"after loop1-------------\")  \n",
        "    clear_output(wait=True)\n",
        "    for inp, tar in image_ds_testA_B.take(1):\n",
        "      generate_images(generator, inp, tar)\n",
        "\n",
        "    # saving (checkpoint) the model every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngXLySdSydzQ",
        "colab_type": "code",
        "outputId": "eaf8fc26-7f64-46a4-869e-99be261b0616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "EPOCHS = 200\n",
        "print(image_ds_trainA_B)\n",
        "train(image_ds_trainA_B, EPOCHS)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 3, 128, 128), (None, 3, 128, 128)), types: (tf.float32, tf.float32)>\n",
            "loop\n",
            "train step\n",
            "train\n",
            "AB:\n",
            "BAB\n",
            "end train step\n",
            "train step\n",
            "train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-227-4122fd280012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ds_trainA_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ds_trainA_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-226-a5a94a1895ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loop1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_canonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1578\u001b[0m           or call_context_key not in self._function_cache.missed):\n\u001b[1;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1513\u001b[0m         self._function_attributes)\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    692\u001b[0m                                           converted_func)\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, IndexedSlices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                   \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                   \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m               ), args, kwargs)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Wrapping around a decorator allows checks like tf_inspect.getargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/tmpsg1_9vjs.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcond_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m                       base_layer_utils.AutoAddUpdates(self,\n\u001b[1;32m    611\u001b[0m                                                       inputs)) as auto_updater:\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mauto_updater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    868\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m                       base_layer_utils.AutoAddUpdates(self,\n\u001b[1;32m    611\u001b[0m                                                       inputs)) as auto_updater:\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mauto_updater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-204-26c0b089122a>\u001b[0m in \u001b[0;36mINLReLU\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mINLReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInstanceNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m           \u001b[0;31m# Explicitly pass the learning phase placeholder to `call` if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m           \u001b[0;31m# the `training` argument was left unspecified by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_addons/layers/normalizations.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_input_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_gamma_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_beta_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_addons/layers/normalizations.py\u001b[0m in \u001b[0;36m_add_gamma_weight\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 constraint=self.gamma_constraint)\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    620\u001b[0m     new_variable = getter(\n\u001b[1;32m    621\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m    153\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;34m\"\"\"To avoid capturing loop variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36minvalid_creator_scope\u001b[0;34m(*unused_args, **unused_kwds)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;34m\"\"\"Disables variable creation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       raise ValueError(\n\u001b[0;32m--> 375\u001b[0;31m           \u001b[0;34m\"tf.function-decorated function tried to create \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m           \"variables on non-first call.\")\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.function-decorated function tried to create variables on non-first call."
          ]
        }
      ]
    }
  ]
}